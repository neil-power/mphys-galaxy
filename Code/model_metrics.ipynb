{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard_reducer as tbr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_PATH = \"lightning_logs/\"\n",
    "def get_metrics(model_folder):\n",
    "    log_data = tbr.load_tb_events([LOG_PATH+model_folder], verbose=True) #,strict_tags=False,strict_steps=False,handle_dup_steps='keep-first')\n",
    "    epochs = log_data['epoch'].values\n",
    "    train_loss_epoch = log_data['train_loss_epoch'].values\n",
    "    train_acc_epoch = log_data['train_acc_epoch'].values\n",
    "    val_loss = log_data['val_loss'].values\n",
    "    val_acc = log_data['val_acc'].values\n",
    "    steps = log_data.keys()\n",
    "    print(len(steps))\n",
    "    for key in log_data:\n",
    "        print(key)\n",
    "        print(len(log_data[key]))\n",
    "    return steps,epochs, train_loss_epoch,train_acc_epoch,val_loss,val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Literal, get_args\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorboard_reducer.event_loader import EventAccumulator\n",
    "\n",
    "def get_metrics2(model_folder):\n",
    "    dirname = LOG_PATH+model_folder\n",
    "    accumulator =     EventAccumulator(dirname).Reload()\n",
    "    load_dict = defaultdict(list)\n",
    "    for tag in accumulator.scalar_tags:\n",
    "        # accumulator.Scalars() returns columns 'step', 'wall_time', 'value'\n",
    "        df_scalar = pd.DataFrame(accumulator.Scalars(tag)).set_index(\"step\")\n",
    "        df_scalar = df_scalar.drop(columns=\"wall_time\")\n",
    "        load_dict[tag].append(df_scalar)\n",
    "    out_dict: dict[str, pd.DataFrame] = {}\n",
    "\n",
    "    out_dict = {\n",
    "        key: pd.concat(lst, join=\"inner\", axis=1) for key, lst in load_dict.items()\n",
    "    }\n",
    "    for key in out_dict:\n",
    "        print(key)\n",
    "        print(len(out_dict[key]))\n",
    "    return out_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss_step\n",
      "63\n",
      "train_acc_step\n",
      "63\n",
      "epoch\n",
      "183\n",
      "val_loss\n",
      "60\n",
      "val_acc\n",
      "60\n",
      "train_loss_epoch\n",
      "60\n",
      "train_acc_epoch\n",
      "60\n",
      "{'train_loss_step':          value\n",
      "step          \n",
      "49    0.650718\n",
      "99    0.383621\n",
      "149   0.318134\n",
      "199   0.251679\n",
      "249   0.253420\n",
      "...        ...\n",
      "2949  0.222659\n",
      "2999  0.218136\n",
      "3049  0.212591\n",
      "3099  0.220684\n",
      "3149  0.213404\n",
      "\n",
      "[63 rows x 1 columns], 'train_acc_step':       value\n",
      "step       \n",
      "49     0.74\n",
      "99     0.93\n",
      "149    0.96\n",
      "199    1.00\n",
      "249    1.00\n",
      "...     ...\n",
      "2949   1.00\n",
      "2999   1.00\n",
      "3049   1.00\n",
      "3099   1.00\n",
      "3149   1.00\n",
      "\n",
      "[63 rows x 1 columns], 'epoch':       value\n",
      "step       \n",
      "49      0.0\n",
      "52      0.0\n",
      "52      0.0\n",
      "99      1.0\n",
      "105     1.0\n",
      "...     ...\n",
      "3126   58.0\n",
      "3126   58.0\n",
      "3149   59.0\n",
      "3179   59.0\n",
      "3179   59.0\n",
      "\n",
      "[183 rows x 1 columns], 'val_loss':          value\n",
      "step          \n",
      "52    1.235157\n",
      "105   0.672453\n",
      "158   0.397136\n",
      "211   0.398125\n",
      "264   0.397894\n",
      "317   0.406826\n",
      "370   0.396089\n",
      "423   0.415718\n",
      "476   0.403996\n",
      "529   0.419049\n",
      "582   0.413731\n",
      "635   0.442042\n",
      "688   0.414572\n",
      "741   0.411839\n",
      "794   0.414390\n",
      "847   0.410674\n",
      "900   0.420705\n",
      "953   0.407949\n",
      "1006  0.408973\n",
      "1059  0.414357\n",
      "1112  0.400673\n",
      "1165  0.405379\n",
      "1218  0.426340\n",
      "1271  0.419042\n",
      "1324  0.419032\n",
      "1377  0.405299\n",
      "1430  0.418497\n",
      "1483  0.398282\n",
      "1536  0.400287\n",
      "1589  0.403521\n",
      "1642  0.414687\n",
      "1695  0.396010\n",
      "1748  0.395876\n",
      "1801  0.402673\n",
      "1854  0.401492\n",
      "1907  0.417253\n",
      "1960  0.396996\n",
      "2013  0.398225\n",
      "2066  0.417878\n",
      "2119  0.395857\n",
      "2172  0.395079\n",
      "2225  0.398439\n",
      "2278  0.398897\n",
      "2331  0.394749\n",
      "2384  0.404074\n",
      "2437  0.396794\n",
      "2490  0.396223\n",
      "2543  0.400981\n",
      "2596  0.410137\n",
      "2649  0.398574\n",
      "2702  0.399952\n",
      "2755  0.402871\n",
      "2808  0.406752\n",
      "2861  0.410671\n",
      "2914  0.405321\n",
      "2967  0.408349\n",
      "3020  0.403201\n",
      "3073  0.395250\n",
      "3126  0.400715\n",
      "3179  0.402172, 'val_acc':          value\n",
      "step          \n",
      "52    0.333333\n",
      "105   0.732000\n",
      "158   0.922667\n",
      "211   0.924000\n",
      "264   0.924444\n",
      "317   0.921778\n",
      "370   0.931111\n",
      "423   0.918667\n",
      "476   0.922667\n",
      "529   0.914222\n",
      "582   0.917778\n",
      "635   0.914667\n",
      "688   0.925333\n",
      "741   0.924444\n",
      "794   0.926667\n",
      "847   0.919111\n",
      "900   0.914667\n",
      "953   0.924444\n",
      "1006  0.927556\n",
      "1059  0.916000\n",
      "1112  0.929778\n",
      "1165  0.929778\n",
      "1218  0.928000\n",
      "1271  0.919111\n",
      "1324  0.916000\n",
      "1377  0.928889\n",
      "1430  0.920444\n",
      "1483  0.932444\n",
      "1536  0.927556\n",
      "1589  0.931111\n",
      "1642  0.920889\n",
      "1695  0.940889\n",
      "1748  0.934222\n",
      "1801  0.934222\n",
      "1854  0.931556\n",
      "1907  0.918222\n",
      "1960  0.939111\n",
      "2013  0.931111\n",
      "2066  0.920444\n",
      "2119  0.937333\n",
      "2172  0.938667\n",
      "2225  0.929778\n",
      "2278  0.931111\n",
      "2331  0.938222\n",
      "2384  0.928000\n",
      "2437  0.937778\n",
      "2490  0.937333\n",
      "2543  0.932889\n",
      "2596  0.924000\n",
      "2649  0.935556\n",
      "2702  0.932889\n",
      "2755  0.928889\n",
      "2808  0.924000\n",
      "2861  0.923111\n",
      "2914  0.931111\n",
      "2967  0.923556\n",
      "3020  0.930222\n",
      "3073  0.940444\n",
      "3126  0.932444\n",
      "3179  0.930222, 'train_loss_epoch':          value\n",
      "step          \n",
      "52    0.724294\n",
      "105   0.462972\n",
      "158   0.316879\n",
      "211   0.266841\n",
      "264   0.250748\n",
      "317   0.242533\n",
      "370   0.238101\n",
      "423   0.232804\n",
      "476   0.230068\n",
      "529   0.228599\n",
      "582   0.227145\n",
      "635   0.226392\n",
      "688   0.226047\n",
      "741   0.225309\n",
      "794   0.224697\n",
      "847   0.223543\n",
      "900   0.222131\n",
      "953   0.221715\n",
      "1006  0.221218\n",
      "1059  0.220544\n",
      "1112  0.219872\n",
      "1165  0.219275\n",
      "1218  0.219585\n",
      "1271  0.219619\n",
      "1324  0.219521\n",
      "1377  0.218717\n",
      "1430  0.218372\n",
      "1483  0.217584\n",
      "1536  0.217779\n",
      "1589  0.217368\n",
      "1642  0.217329\n",
      "1695  0.216906\n",
      "1748  0.217248\n",
      "1801  0.216651\n",
      "1854  0.216675\n",
      "1907  0.216417\n",
      "1960  0.216767\n",
      "2013  0.215941\n",
      "2066  0.216268\n",
      "2119  0.216521\n",
      "2172  0.215987\n",
      "2225  0.215742\n",
      "2278  0.215111\n",
      "2331  0.215635\n",
      "2384  0.216011\n",
      "2437  0.215729\n",
      "2490  0.215340\n",
      "2543  0.214929\n",
      "2596  0.215364\n",
      "2649  0.215566\n",
      "2702  0.215357\n",
      "2755  0.215122\n",
      "2808  0.215470\n",
      "2861  0.215465\n",
      "2914  0.214944\n",
      "2967  0.214995\n",
      "3020  0.215065\n",
      "3073  0.214752\n",
      "3126  0.214401\n",
      "3179  0.214182, 'train_acc_epoch':          value\n",
      "step          \n",
      "52    0.667619\n",
      "105   0.895524\n",
      "158   0.972667\n",
      "211   0.996667\n",
      "264   0.999619\n",
      "317   1.000000\n",
      "370   1.000000\n",
      "423   0.999905\n",
      "476   1.000000\n",
      "529   1.000000\n",
      "582   0.999905\n",
      "635   0.999714\n",
      "688   0.999714\n",
      "741   0.999810\n",
      "794   1.000000\n",
      "847   0.999905\n",
      "900   0.999905\n",
      "953   1.000000\n",
      "1006  0.999905\n",
      "1059  1.000000\n",
      "1112  1.000000\n",
      "1165  1.000000\n",
      "1218  1.000000\n",
      "1271  1.000000\n",
      "1324  1.000000\n",
      "1377  1.000000\n",
      "1430  1.000000\n",
      "1483  1.000000\n",
      "1536  1.000000\n",
      "1589  1.000000\n",
      "1642  1.000000\n",
      "1695  1.000000\n",
      "1748  1.000000\n",
      "1801  1.000000\n",
      "1854  1.000000\n",
      "1907  1.000000\n",
      "1960  1.000000\n",
      "2013  1.000000\n",
      "2066  1.000000\n",
      "2119  1.000000\n",
      "2172  1.000000\n",
      "2225  1.000000\n",
      "2278  1.000000\n",
      "2331  1.000000\n",
      "2384  1.000000\n",
      "2437  1.000000\n",
      "2490  1.000000\n",
      "2543  1.000000\n",
      "2596  1.000000\n",
      "2649  1.000000\n",
      "2702  1.000000\n",
      "2755  1.000000\n",
      "2808  1.000000\n",
      "2861  1.000000\n",
      "2914  1.000000\n",
      "2967  1.000000\n",
      "3020  1.000000\n",
      "3073  1.000000\n",
      "3126  1.000000\n",
      "3179  1.000000}\n"
     ]
    }
   ],
   "source": [
    "t = get_metrics2('resnet_18_best_subset')\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading runs: 100%|██████████| 1/1 [00:00<00:00, 39.41it/s]\n",
      "Reading tags:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading tags:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tag 'epoch' from run directory 'lightning_logs/resnet_18_best_subset' contains duplicate steps. Please make sure your data wasn't corrupted. If this is expected/you want to proceed anyway, specify how to handle duplicate values recorded for the same tag and step in a single run by passing --handle-dup-steps to the CLI or handle_dup_steps='keep-first'|'keep-last'|'mean' to the Python API. This will keep the first/last occurrence of duplicate steps or take their mean.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m steps, epochs, train_loss,train_acc,val_loss,val_acc \u001b[38;5;241m=\u001b[39m get_metrics(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresnet_18_best_subset\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      3\u001b[0m ax1 \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39madd_subplot(\u001b[38;5;241m221\u001b[39m) \n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36mget_metrics\u001b[0;34m(model_folder)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_metrics\u001b[39m(model_folder):\n\u001b[0;32m----> 3\u001b[0m     log_data \u001b[38;5;241m=\u001b[39m tbr\u001b[38;5;241m.\u001b[39mload_tb_events([LOG_PATH\u001b[38;5;241m+\u001b[39mmodel_folder], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#,strict_tags=False,strict_steps=False,handle_dup_steps='keep-first')\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     epochs \u001b[38;5;241m=\u001b[39m log_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      5\u001b[0m     train_loss_epoch \u001b[38;5;241m=\u001b[39m log_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m/share/nas2/npower/miniconda3/envs/mphys-galaxy/lib/python3.11/site-packages/tensorboard_reducer/load.py:109\u001b[0m, in \u001b[0;36mload_tb_events\u001b[0;34m(input_dirs, strict_tags, strict_steps, handle_dup_steps, min_runs_per_step, verbose)\u001b[0m\n\u001b[1;32m    106\u001b[0m df_scalar \u001b[38;5;241m=\u001b[39m df_scalar\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwall_time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle_dup_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df_scalar\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTag \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m from run directory \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m contains duplicate \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps. Please make sure your data wasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt corrupted. If this is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected/you want to proceed anyway, specify how to handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduplicate values recorded for the same tag and step in a single \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun by passing --handle-dup-steps to the CLI or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandle_dup_steps=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeep-first\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeep-last\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to the Python \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI. This will keep the first/last occurrence of duplicate steps \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor take their mean.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m     )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle_dup_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    120\u001b[0m     df_scalar \u001b[38;5;241m=\u001b[39m df_scalar\u001b[38;5;241m.\u001b[39mgroupby(df_scalar\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mValueError\u001b[0m: Tag 'epoch' from run directory 'lightning_logs/resnet_18_best_subset' contains duplicate steps. Please make sure your data wasn't corrupted. If this is expected/you want to proceed anyway, specify how to handle duplicate values recorded for the same tag and step in a single run by passing --handle-dup-steps to the CLI or handle_dup_steps='keep-first'|'keep-last'|'mean' to the Python API. This will keep the first/last occurrence of duplicate steps or take their mean."
     ]
    }
   ],
   "source": [
    "steps, epochs, train_loss,train_acc,val_loss,val_acc = get_metrics('resnet_18_best_subset')\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "ax1 = fig.add_subplot(221) \n",
    "ax1.plot(steps,train_loss,linestyle='-', c='orange')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Train Loss')\n",
    "\n",
    "ax2 = fig.add_subplot(222) \n",
    "ax2.plot(steps,val_loss,linestyle='-', c='violet')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Validation Loss')\n",
    "\n",
    "ax3 = fig.add_subplot(223) \n",
    "ax3.plot(steps,train_acc,linestyle='-', c='red')\n",
    "ax3.set_xlabel('Epochs')\n",
    "ax3.set_ylabel('Train Accuracy')\n",
    "\n",
    "ax4 = fig.add_subplot(224) \n",
    "ax4.plot(steps,val_acc,linestyle='-', c='green')\n",
    "ax4.set_xlabel('Epochs')\n",
    "ax4.set_ylabel('Validation Accuracy')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mphys-galaxy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

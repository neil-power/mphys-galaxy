{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the default resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\mphys-galaxy\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import matplotlib as plt\n",
    "from torch import Tensor\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "#from typing import Type, Any, Callable, Union, List, Optional, Tuple\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset,Subset\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "CATALOG_PATH = '../Data/subset_gz1_desi_cross_cat.csv'\n",
    "DATA_PATH = '../Data/Subset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "#Run processes on CPU or GPU\n",
    "if USE_GPU:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if device.type == 'cuda':\n",
    "        print(torch.cuda.get_device_name(0))\n",
    "        print('Memory Usage:')\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1500 galaxy images\n"
     ]
    }
   ],
   "source": [
    "catalog = pd.read_csv(CATALOG_PATH)\n",
    "print(f\"Loaded {catalog.shape[0]} galaxy images\")\n",
    "\n",
    "#Select features (clockwise and anti-clockwise probabilities)\n",
    "Y = catalog[['P_CW','P_ACW']]\n",
    "classes = [r'P_CW',r'P_ACW']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate list of file locations from catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths(catalog_to_convert,folder_path ):\n",
    "    brick_ids = catalog_to_convert['dr8_id'].str.split(\"_\",expand=True)[0]\n",
    "    dr8_ids = catalog_to_convert['dr8_id']\n",
    "    file_locations = folder_path+'/'+brick_ids+'/'+dr8_ids+'.jpg'\n",
    "    return file_locations\n",
    "\n",
    "file_locations = get_file_paths(catalog,DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR = True\n",
    "RAW_SIZE = 15\n",
    "IMG_SIZE = 160\n",
    "\n",
    "TARGET_SIZE = 5\n",
    "TRANSLATE = 0.\n",
    "ROTATE = False\n",
    "FLIP = False\n",
    "LABEL = 2\n",
    "SHUFFLE = False\n",
    "\n",
    "\n",
    "def img_proc(img, raw_size=RAW_SIZE, target_size=TARGET_SIZE, translate=TRANSLATE, rotate=ROTATE,\n",
    "             random_generator=None):\n",
    "    assert img.shape[-2] == img.shape[-1]\n",
    "    assert translate >= 0\n",
    "    \n",
    "    if random_generator is None:\n",
    "        random_generator = int.from_bytes(os.urandom(4), byteorder='little')\n",
    "    rng = np.random.default_rng(random_generator)\n",
    "\n",
    "    if not isinstance(target_size, (float, int)):\n",
    "        target_size = rng.uniform(*target_size)\n",
    "    if rotate:\n",
    "        assert target_size * (1 + translate) * 2**0.5 < raw_size\n",
    "        if isinstance(rotate, bool):\n",
    "            rotate = rng.uniform(0., 360.)\n",
    "        img = ndimage.rotate(img, rotate, axes=(-1, -2), reshape=False, order=1)\n",
    "    else:\n",
    "        assert target_size * (1 + translate) < raw_size\n",
    "    s = img.shape[-1]\n",
    "    translate = translate * target_size\n",
    "    t_x = rng.uniform(-translate, translate) if translate > 0 else 0\n",
    "    t_y = rng.uniform(-translate, translate) if translate > 0 else 0\n",
    "    a = int(s * (raw_size - target_size + t_x) / (2 * raw_size))\n",
    "    b = int(s * (raw_size - target_size + t_y) / (2 * raw_size))\n",
    "    c = int(s * target_size / raw_size)\n",
    "    return img[..., a:(a + c), b:(b + c)]\n",
    "\n",
    "\n",
    "def read_img(path, color=COLOR, img_size=IMG_SIZE, atleast_3d=True, random_flip=FLIP,\n",
    "             shuffle_channel=SHUFFLE, random_generator=None, **kwargs):\n",
    "    if random_generator is None:\n",
    "        random_generator = int.from_bytes(os.urandom(4), byteorder='little')\n",
    "    rng = np.random.default_rng(random_generator)\n",
    "\n",
    "    jpeg_file = (np.asarray(Image.open(path)) / 255).astype(np.float32)\n",
    "    if color:\n",
    "        img = np.moveaxis(jpeg_file, -1, 0)\n",
    "        if shuffle_channel:\n",
    "            if isinstance(shuffle_channel, bool):\n",
    "                shuffle_channel = rng.permutation(img.shape[0])\n",
    "            img = img[shuffle_channel]\n",
    "    else:\n",
    "        img = np.mean(jpeg_file, axis=-1)\n",
    "    img = img_proc(img, random_generator=rng, **kwargs)\n",
    "    rng.uniform(size=100) # just to jump the rng\n",
    "\n",
    "    if img_size is not None:\n",
    "        z = img_size / img.shape[-1]\n",
    "        if img.ndim == 2:\n",
    "            img = ndimage.zoom(img, (z, z), order=1)\n",
    "            if atleast_3d:\n",
    "                img = img[np.newaxis]\n",
    "        elif img.ndim == 3:\n",
    "            img = ndimage.zoom(img, (1, z, z), order=1)\n",
    "        else:\n",
    "            raise RuntimeError\n",
    "\n",
    "    if random_flip:\n",
    "        flip = int(rng.integers(0, 2, 1))\n",
    "        flip = 2 * flip - 1\n",
    "    else:\n",
    "        flip = 1\n",
    "    return np.ascontiguousarray(img[..., ::flip])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes 2 mins 20\n",
    "X = torch.empty(0, 3, 160,160)\n",
    "for i in range(len(file_locations)):\n",
    "    X = torch.cat((X, torch.from_numpy(read_img(file_locations[i])).float()[np.newaxis]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1500 images\n"
     ]
    }
   ],
   "source": [
    "print(f\"Processed {X.shape[0]} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = resnet18(num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "weight_decay = 1\n",
    "\n",
    "num_epochs = 120\n",
    "batch_size = 60 #60\n",
    "\n",
    "modfile = 'modfile.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to train the model on data\n",
    "def train(model, trainloader, optimiser, device):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, labels) in enumerate(trainloader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        #calculate train loss\n",
    "        output = model(data)\n",
    "        loss_criterion = nn.CrossEntropyLoss()\n",
    "        labels = labels.to(device)        \n",
    "        loss = loss_criterion(output, labels)\n",
    "            \n",
    "        train_loss += loss.item() * data.size(0)\n",
    "\n",
    "        #feed the loss back\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "    train_loss /= len(trainloader.dataset)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to test the model on data\n",
    "def validate(model, testloader, device):\n",
    "    prediction=[]\n",
    "    target=[]\n",
    "    correct = 0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, labels) in enumerate(testloader):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            p_y = model(data)\n",
    "            #calculate test loss\n",
    "            loss_criterion = nn.CrossEntropyLoss()\n",
    "            #labels = labels.type(torch.LongTensor)\n",
    "            labels = labels.to(device)\n",
    "            loss = loss_criterion(p_y, labels)\n",
    "                \n",
    "            test_loss += loss.item() * data.size(0)\n",
    "            \n",
    "            #values for metrics\n",
    "            #preds = p_y.argmax(dim=1, keepdim=True)\n",
    "            #correct += preds.eq(labels.view_as(preds)).sum().item()\n",
    "            #prediction+=preds.squeeze(1).tolist()\n",
    "            #target+=labels.tolist()\n",
    "        test_loss /= len(testloader.dataset)\n",
    "        accuracy = correct / len(testloader.dataset)\n",
    "\n",
    "        #calculate ROC score metric\n",
    "            # roc_auc = roc_auc_score(target, prediction)\n",
    "            # recall = recall_score(target, prediction)\n",
    "            # f1 = f1_score(target, prediction)\n",
    "            # precision = precision_score(target, prediction)\n",
    "    return test_loss, accuracy#, roc_auc, prediction, target, recall, f1, precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(frac_val, data):\n",
    "    dataset_size = len(data)\n",
    "    nval = int(frac_val*dataset_size)\n",
    "\n",
    "    indices = list(range(dataset_size))\n",
    "    train_indices, val_indices = indices[nval:], indices[:nval]\n",
    "\n",
    "    train_sampler = Subset(data, train_indices)\n",
    "    valid_sampler = Subset(data, val_indices)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_sampler, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(valid_sampler, batch_size=batch_size, shuffle=True)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to run the entire model train/test loop\n",
    "TEST_USE = False\n",
    "early_stopping = True\n",
    "QUIET = False\n",
    "def run_func(X,Y,model):\n",
    "    X_tensor = X\n",
    "    Y_tensor = torch.from_numpy(Y.values).float()\n",
    "\n",
    "    dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "    train_loader,val_loader = data_split(0.7,dataset)\n",
    "\n",
    "    #optimizer and learning rate scheduler\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay = weight_decay)#0.005, #0.01\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.15)\n",
    "\n",
    "    #array to store metrics\n",
    "    result_arr = np.zeros((num_epochs,4))\n",
    "\n",
    "    _bestloss = 1.\n",
    "    #NN learning\n",
    "    for epoch in range(num_epochs):\n",
    "    \n",
    "        train_loss = train(model, train_loader, optimizer, device)\n",
    "        val_loss, accuracy= validate(model, val_loader, device)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if early_stopping and val_loss<_bestloss:\n",
    "            _bestloss = val_loss\n",
    "            torch.save(model.state_dict(), modfile)\n",
    "            best_epoch = epoch\n",
    "            #cm = confusion_matrix(target, prediction,normalize = 'true')\n",
    "\n",
    "        #set output row\n",
    "        results = [epoch, train_loss, val_loss, accuracy]\n",
    "        result_arr[epoch] = results\n",
    "\n",
    "        #print epoch results\n",
    "        if not QUIET:\n",
    "            print('Epoch: {}, Validation Loss: {:4f}, Validation Accuracy: {:4f}'.format(epoch, val_loss, accuracy))\n",
    "            print('Current learning rate is: {}'.format(optimizer.param_groups[0]['lr']))\n",
    "    \n",
    "    test_arr=[]\n",
    "    if TEST_USE:\n",
    "        #Test data run\n",
    "        bestmodel=selected_model().to(device)\n",
    "        bestmodel.load_state_dict(torch.load('modfile.pt'))\n",
    "        test_loss, test_accuracy, test_auc, prediction2,target2,  recall2, f12, precision2 = validate(bestmodel, test_loader, device)\n",
    "        test_arr=[test_loss, test_accuracy, test_auc, prediction2,target2,  recall2, f12, precision2]\n",
    "\n",
    "    if not early_stopping:\n",
    "        torch.save(model.state_dict(), modfile)\n",
    "        best_epoch = -1\n",
    "        #cm = confusion_matrix(target, prediction,normalize = 'true')\n",
    "\n",
    "    return result_arr, test_arr, best_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actually run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result_arr1, test_arr1, best_epoch \u001b[38;5;241m=\u001b[39m run_func(X,Y,selected_model)\n",
      "Cell \u001b[1;32mIn[14], line 27\u001b[0m, in \u001b[0;36mrun_func\u001b[1;34m(X, Y, model)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m     26\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train(model, train_loader, optimizer, device)\n\u001b[1;32m---> 27\u001b[0m     val_loss, accuracy\u001b[38;5;241m=\u001b[39m validate(model, val_loader, device)\n\u001b[0;32m     29\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(val_loss)\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m early_stopping \u001b[38;5;129;01mand\u001b[39;00m val_loss\u001b[38;5;241m<\u001b[39m_bestloss:\n",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m, in \u001b[0;36mvalidate\u001b[1;34m(model, testloader, device)\u001b[0m\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(testloader):\n\u001b[0;32m     11\u001b[0m         data, labels \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     13\u001b[0m         p_y \u001b[38;5;241m=\u001b[39m model(data)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\mphys-galaxy\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\mphys-galaxy\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\mphys-galaxy\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\mphys-galaxy\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\mphys-galaxy\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "result_arr1, test_arr1, best_epoch = run_func(X,Y,selected_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mphys-moon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

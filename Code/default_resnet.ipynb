{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the default resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\mphys-galaxy\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import Tensor\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "#from typing import Type, Any, Callable, Union, List, Optional, Tuple\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset,Subset\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "CATALOG_PATH = '../Data/subset_gz1_desi_cross_cat.csv'\n",
    "DATA_PATH = '../Data/Subset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "#Run processes on CPU or GPU\n",
    "if USE_GPU:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if device.type == 'cuda':\n",
    "        print(torch.cuda.get_device_name(0))\n",
    "        print('Memory Usage:')\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1500 galaxy images\n"
     ]
    }
   ],
   "source": [
    "catalog = pd.read_csv(CATALOG_PATH)\n",
    "print(f\"Loaded {catalog.shape[0]} galaxy images\")\n",
    "\n",
    "#Select features (clockwise and anti-clockwise probabilities)\n",
    "Y = catalog[['P_CW','P_ACW']]\n",
    "classes = [r'P_CW',r'P_ACW']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate list of file locations from catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths(catalog_to_convert,folder_path ):\n",
    "    brick_ids = catalog_to_convert['dr8_id'].str.split(\"_\",expand=True)[0]\n",
    "    dr8_ids = catalog_to_convert['dr8_id']\n",
    "    file_locations = folder_path+'/'+brick_ids+'/'+dr8_ids+'.jpg'\n",
    "    return file_locations\n",
    "\n",
    "file_locations = get_file_paths(catalog,DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR = True\n",
    "RAW_SIZE = 15\n",
    "IMG_SIZE = 160\n",
    "\n",
    "TARGET_SIZE = 5\n",
    "TRANSLATE = 0.\n",
    "ROTATE = False\n",
    "FLIP = False\n",
    "LABEL = 2\n",
    "SHUFFLE = False\n",
    "\n",
    "\n",
    "def img_proc(img, raw_size=RAW_SIZE, target_size=TARGET_SIZE, translate=TRANSLATE, rotate=ROTATE,\n",
    "             random_generator=None):\n",
    "    assert img.shape[-2] == img.shape[-1]\n",
    "    assert translate >= 0\n",
    "    \n",
    "    if random_generator is None:\n",
    "        random_generator = int.from_bytes(os.urandom(4), byteorder='little')\n",
    "    rng = np.random.default_rng(random_generator)\n",
    "\n",
    "    if not isinstance(target_size, (float, int)):\n",
    "        target_size = rng.uniform(*target_size)\n",
    "    if rotate:\n",
    "        assert target_size * (1 + translate) * 2**0.5 < raw_size\n",
    "        if isinstance(rotate, bool):\n",
    "            rotate = rng.uniform(0., 360.)\n",
    "        img = ndimage.rotate(img, rotate, axes=(-1, -2), reshape=False, order=1)\n",
    "    else:\n",
    "        assert target_size * (1 + translate) < raw_size\n",
    "    s = img.shape[-1]\n",
    "    translate = translate * target_size\n",
    "    t_x = rng.uniform(-translate, translate) if translate > 0 else 0\n",
    "    t_y = rng.uniform(-translate, translate) if translate > 0 else 0\n",
    "    a = int(s * (raw_size - target_size + t_x) / (2 * raw_size))\n",
    "    b = int(s * (raw_size - target_size + t_y) / (2 * raw_size))\n",
    "    c = int(s * target_size / raw_size)\n",
    "    return img[..., a:(a + c), b:(b + c)]\n",
    "\n",
    "\n",
    "def read_img(path, color=COLOR, img_size=IMG_SIZE, atleast_3d=True, random_flip=FLIP,\n",
    "             shuffle_channel=SHUFFLE, random_generator=None, **kwargs):\n",
    "    if random_generator is None:\n",
    "        random_generator = int.from_bytes(os.urandom(4), byteorder='little')\n",
    "    rng = np.random.default_rng(random_generator)\n",
    "\n",
    "    jpeg_file = (np.asarray(Image.open(path)) / 255).astype(np.float32)\n",
    "    if color:\n",
    "        img = np.moveaxis(jpeg_file, -1, 0)\n",
    "        if shuffle_channel:\n",
    "            if isinstance(shuffle_channel, bool):\n",
    "                shuffle_channel = rng.permutation(img.shape[0])\n",
    "            img = img[shuffle_channel]\n",
    "    else:\n",
    "        img = np.mean(jpeg_file, axis=-1)\n",
    "    img = img_proc(img, random_generator=rng, **kwargs)\n",
    "    rng.uniform(size=100) # just to jump the rng\n",
    "\n",
    "    if img_size is not None:\n",
    "        z = img_size / img.shape[-1]\n",
    "        if img.ndim == 2:\n",
    "            img = ndimage.zoom(img, (z, z), order=1)\n",
    "            if atleast_3d:\n",
    "                img = img[np.newaxis]\n",
    "        elif img.ndim == 3:\n",
    "            img = ndimage.zoom(img, (1, z, z), order=1)\n",
    "        else:\n",
    "            raise RuntimeError\n",
    "\n",
    "    if random_flip:\n",
    "        flip = int(rng.integers(0, 2, 1))\n",
    "        flip = 2 * flip - 1\n",
    "    else:\n",
    "        flip = 1\n",
    "    return np.ascontiguousarray(img[..., ::flip])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes 2 mins 20\n",
    "X = torch.empty(0, 3, 160,160)\n",
    "for i in range(len(file_locations)):\n",
    "    X = torch.cat((X, torch.from_numpy(read_img(file_locations[i])).float()[np.newaxis]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1500 images\n"
     ]
    }
   ],
   "source": [
    "print(f\"Processed {X.shape[0]} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = resnet18(num_classes=2)\n",
    "if torch.cuda.is_available():\n",
    "    selected_model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "weight_decay = 1\n",
    "\n",
    "num_epochs = 120\n",
    "batch_size = 60 #60\n",
    "\n",
    "modfile = 'resnet18_modfile.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, optimiser, device):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, labels) in enumerate(trainloader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        #Calculate train loss\n",
    "        #Softmax output and labels for passing to cross-entropy function\n",
    "        p_y = model(data).softmax(dim=1)\n",
    "        labels = labels.softmax(dim=1).to(device) \n",
    "\n",
    "        loss_criterion = nn.CrossEntropyLoss()\n",
    "        loss = loss_criterion(p_y, labels)\n",
    "            \n",
    "        train_loss += loss.item() * data.size(0)\n",
    "        \n",
    "        #Feed the loss back\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "    train_loss /= len(trainloader.dataset)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to test the model on data\n",
    "def validate(model, testloader, device):\n",
    "    correct = 0\n",
    "    test_loss = 0.0\n",
    "    mse_loss = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, labels) in enumerate(testloader):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            #Softmax output and labels for passing to cross-entropy function\n",
    "            p_y = model(data).softmax(dim=1)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            #Calculate test loss         \n",
    "            loss_criterion = nn.CrossEntropyLoss()\n",
    "            loss = loss_criterion(p_y, labels)\n",
    "            test_loss += loss.item() * data.size(0)\n",
    "\n",
    "        test_loss /= len(testloader.dataset)\n",
    "        \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(frac_val, data):\n",
    "    dataset_size = len(data)\n",
    "    nval = int(frac_val*dataset_size)\n",
    "\n",
    "    indices = list(range(dataset_size))\n",
    "    train_indices, val_indices = indices[nval:], indices[:nval]\n",
    "\n",
    "    train_sampler = Subset(data, train_indices)\n",
    "    valid_sampler = Subset(data, val_indices)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_sampler, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(valid_sampler, batch_size=batch_size, shuffle=True)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to run the entire model train/test loop\n",
    "TEST_USE = False\n",
    "early_stopping = True\n",
    "QUIET = False\n",
    "\n",
    "def test_train_model(X,Y,model):\n",
    "    X_tensor = X\n",
    "    Y_tensor = torch.from_numpy(Y.values).float()\n",
    "\n",
    "    dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "    train_loader,val_loader = data_split(0.7,dataset)\n",
    "\n",
    "    if TEST_USE: #Doesn't currently work\n",
    "        val_loader, test_loader = data_split(0.5,val_loader)\n",
    "\n",
    "    #optimizer and learning rate scheduler\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay = weight_decay)#0.005, #0.01\n",
    "    #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.85)\n",
    "\n",
    "    #array to store metrics\n",
    "    result_arr = np.zeros((num_epochs,4))\n",
    "\n",
    "    _bestloss = 1.\n",
    "    #NN learning\n",
    "    for epoch in range(num_epochs):\n",
    "    \n",
    "        train_loss = train(model, train_loader, optimizer, device)\n",
    "        val_loss = validate(model, val_loader, device)\n",
    "        \n",
    "        #scheduler.step() \n",
    "\n",
    "        if early_stopping and val_loss<_bestloss:\n",
    "            _bestloss = val_loss\n",
    "            torch.save(model.state_dict(), modfile)\n",
    "            best_epoch = epoch\n",
    "\n",
    "        #set output row\n",
    "        results = [epoch, train_loss, val_loss]\n",
    "        result_arr[epoch] = results\n",
    "\n",
    "        #print epoch results\n",
    "        if not QUIET:\n",
    "            print(f\"Epoch: {epoch}, Train Loss: {train_loss:4f}, Validation Loss: {val_loss:4f}, Learning Rate: {optimizer.param_groups[0]['lr']:4f}\")\n",
    "    \n",
    "    test_arr=[]\n",
    "    if TEST_USE:\n",
    "        #Test data run\n",
    "        bestmodel=selected_model().to(device)\n",
    "        bestmodel.load_state_dict(torch.load('modfile.pt'))\n",
    "        test_loss, test_accuracy, test_auc, prediction2,target2,  recall2, f12, precision2 = validate(bestmodel, test_loader, device)\n",
    "        test_arr=[test_loss, test_accuracy, test_auc, prediction2,target2,  recall2, f12, precision2]\n",
    "\n",
    "    if not early_stopping:\n",
    "        torch.save(model.state_dict(), modfile)\n",
    "        best_epoch = -1\n",
    "\n",
    "    return result_arr, test_arr, best_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actually run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\mphys-galaxy\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:149: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 0.020931, Validation Loss: 0.618887, MSE Loss: 0.378476\n",
      "Epoch: 1, Train Loss: 0.013708, Validation Loss: 0.617042, MSE Loss: 0.353710\n",
      "Epoch: 2, Train Loss: 0.012033, Validation Loss: 0.660202, MSE Loss: 0.420842\n",
      "Epoch: 3, Train Loss: 0.009693, Validation Loss: 0.627378, MSE Loss: 0.341717\n",
      "Epoch: 4, Train Loss: 0.007285, Validation Loss: 0.648701, MSE Loss: 0.436407\n",
      "Epoch: 5, Train Loss: 0.005792, Validation Loss: 0.667259, MSE Loss: 0.409309\n",
      "Epoch: 6, Train Loss: 0.005397, Validation Loss: 0.735329, MSE Loss: 0.667150\n",
      "Epoch: 7, Train Loss: 0.006796, Validation Loss: 1.060741, MSE Loss: 1.531729\n",
      "Epoch: 8, Train Loss: 0.007640, Validation Loss: 0.761429, MSE Loss: 0.933255\n",
      "Epoch: 9, Train Loss: 0.007148, Validation Loss: 0.815346, MSE Loss: 0.847575\n",
      "Epoch: 10, Train Loss: 0.006320, Validation Loss: 0.744167, MSE Loss: 0.392949\n",
      "Epoch: 11, Train Loss: 0.006130, Validation Loss: 0.881675, MSE Loss: 1.012219\n",
      "Epoch: 12, Train Loss: 0.006646, Validation Loss: 0.877181, MSE Loss: 1.035610\n",
      "Epoch: 13, Train Loss: 0.006806, Validation Loss: 1.007498, MSE Loss: 1.784869\n",
      "Epoch: 14, Train Loss: 0.007432, Validation Loss: 0.944701, MSE Loss: 1.054734\n",
      "Epoch: 15, Train Loss: 0.006456, Validation Loss: 0.724033, MSE Loss: 0.784059\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result_arr1, test_arr1, best_epoch \u001b[38;5;241m=\u001b[39m run_func(X,Y,selected_model)\n",
      "Cell \u001b[1;32mIn[14], line 26\u001b[0m, in \u001b[0;36mrun_func\u001b[1;34m(X, Y, model)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#NN learning\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 26\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train(model, train_loader, optimizer, device)\n\u001b[0;32m     27\u001b[0m     val_loss, mse_loss\u001b[38;5;241m=\u001b[39m validate(model, val_loader, device)\n\u001b[0;32m     29\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(val_loss)\n",
      "Cell \u001b[1;32mIn[11], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, trainloader, optimiser, device)\u001b[0m\n\u001b[0;32m     15\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m#Feed the loss back\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     19\u001b[0m     optimiser\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     21\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(trainloader\u001b[38;5;241m.\u001b[39mdataset)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\mphys-galaxy\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\mphys-galaxy\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result_arr1, test_arr1, best_epoch = test_train_model(X,Y,selected_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_arr1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#plot the training cycle\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(result_arr1[:,\u001b[38;5;241m0\u001b[39m],result_arr1[:,\u001b[38;5;241m3\u001b[39m],linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(result_arr1[:,\u001b[38;5;241m0\u001b[39m],result_arr1[:,\u001b[38;5;241m2\u001b[39m],linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m'\u001b[39m,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(result_arr1[:,\u001b[38;5;241m0\u001b[39m],result_arr1[:,\u001b[38;5;241m1\u001b[39m],linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviolet\u001b[39m\u001b[38;5;124m'\u001b[39m,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result_arr1' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the training cycle\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(result_arr1[:,0],result_arr1[:,3],linestyle='-', label='Accuracy')\n",
    "plt.plot(result_arr1[:,0],result_arr1[:,2],linestyle='-', c='orange',label='Validation loss')\n",
    "plt.plot(result_arr1[:,0],result_arr1[:,1],linestyle='-', c='violet',label='Train loss')\n",
    "plt.ylim(0,1.5)\n",
    "plt.xlim(0,num_epochs-1)\n",
    "plt.title('NN training cycle')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mphys-moon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

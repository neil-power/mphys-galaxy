{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Lightning for ResNet using galaxy_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GZDESI/GZRings/GZCD not available from galaxy_datasets.pytorch.datasets - skipping\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from enum import Enum\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import lightning as pl\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "import albumentations as A\n",
    "from galaxy_datasets.pytorch.galaxy_datamodule import GalaxyDataModule\n",
    "from ChiralityClassifier import ChiralityClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modes(Enum):\n",
    "    FULL_DATASET = 0 #Use all 600,000 galaxies\n",
    "    CUT_DATASET = 1 #Use cut of 200,000 galaxies\n",
    "    BEST_SUBSET = 2 #Select N best S,Z & other galaxies, evenly split\n",
    "    LOCAL_SUBSET = 3 #Use local cache of 1500 galaxies\n",
    "\n",
    "IMG_SIZE = 160 # This is the output size of the generated image array\n",
    "MODE = modes.CUT_DATASET\n",
    "\n",
    "#If using best subset, Number of CW, ACW and EL to select\n",
    "THRESHOLD = 0.8\n",
    "N_CW = 5000\n",
    "N_ACW = 5000\n",
    "N_EL = 5000\n",
    "\n",
    "FULL_CATALOG_PATH = '../Data/gz1_desi_cross_cat.csv'\n",
    "FULL_DATA_PATH = '/share/nas2/walml/galaxy_zoo/decals/dr8/jpg'\n",
    "CUT_CATALOG_PATH = '../Data/gz1_desi_cross_cat_cut.csv'\n",
    "LOCAL_SUBSET_CATALOG_PATH = '../Data/subset_gz1_desi_cross_cat.csv'\n",
    "LOCAL_SUBSET_DATA_PATH = '../Data/Subset'\n",
    "SAVE_PATH = \"../Models\"\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pytorch 2.2.1\n",
      "CPU cores available on device: 24\n",
      "NVIDIA A100-PCIE-40GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "#Check GPU & Torch is working\n",
    "print(f\"Using pytorch {torch.__version__}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"CPU cores available on device: {os.cpu_count()}\")\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 208682 galaxy filepaths\n"
     ]
    }
   ],
   "source": [
    "def get_file_paths(catalog_to_convert,folder_path ):\n",
    "    brick_ids = catalog_to_convert['dr8_id'].str.split(\"_\",expand=True)[0]\n",
    "    dr8_ids = catalog_to_convert['dr8_id']\n",
    "    file_locations = folder_path+'/'+brick_ids+'/'+dr8_ids+'.jpg'\n",
    "    print(f\"Created {file_locations.shape[0]} galaxy filepaths\")\n",
    "    return file_locations\n",
    "\n",
    "if MODE == modes.FULL_DATASET:\n",
    "    catalog = pd.read_csv(FULL_CATALOG_PATH)\n",
    "    catalog['file_loc'] = get_file_paths(catalog,FULL_DATA_PATH)\n",
    "\n",
    "elif MODE == modes.CUT_DATASET:\n",
    "    catalog = pd.read_csv(CUT_CATALOG_PATH)\n",
    "    catalog['file_loc'] = get_file_paths(catalog,FULL_DATA_PATH)\n",
    "\n",
    "elif MODE == modes.BEST_SUBSET:\n",
    "    catalog = pd.read_csv(FULL_CATALOG_PATH)\n",
    "    very_CW_galaxies = catalog[catalog['P_CW']>THRESHOLD]\n",
    "    very_ACW_galaxies = catalog[catalog['P_ACW']>THRESHOLD]\n",
    "    very_EL_galaxies = catalog[catalog['P_EL']>THRESHOLD]\n",
    "    print(f\"Very CW: {very_CW_galaxies.shape[0]}, Very ACW: {very_ACW_galaxies.shape[0]}, Very EL: {very_EL_galaxies.shape[0]}\")\n",
    "\n",
    "    galaxy_subset = pd.concat([very_CW_galaxies[0:N_CW],very_ACW_galaxies[0:N_ACW],very_EL_galaxies[0:N_EL]])\n",
    "    catalog = galaxy_subset.reset_index()\n",
    "    catalog['file_loc'] = get_file_paths(catalog,FULL_DATA_PATH)\n",
    "\n",
    "elif MODE == modes.LOCAL_SUBSET:\n",
    "    catalog = pd.read_csv(LOCAL_SUBSET_CATALOG_PATH)\n",
    "    catalog['file_loc'] = get_file_paths(catalog,LOCAL_SUBSET_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging non-S/Z galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 208682 galaxy images\n"
     ]
    }
   ],
   "source": [
    "catalog['P_OTHER'] = catalog['P_EL']+catalog['P_EDGE']+catalog['P_DK']+catalog['P_MG']\n",
    "print(f\"Loaded {catalog.shape[0]} galaxy images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transforms(resize_after_crop=IMG_SIZE):\n",
    "    transforms_to_apply = [\n",
    "        A.ToFloat(), #Converts from 0-255 to 0-1\n",
    "\n",
    "        A.Resize( #Resizes to 160x160\n",
    "            height=resize_after_crop,\n",
    "            width=resize_after_crop,\n",
    "            interpolation=1,\n",
    "            always_apply=True\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    return A.Compose(transforms_to_apply)\n",
    "\n",
    "datamodule = GalaxyDataModule(\n",
    "    label_cols=['P_CW','P_ACW','P_OTHER'],\n",
    "    catalog=catalog,\n",
    "    train_fraction=0.7,\n",
    "    val_fraction=0.15,\n",
    "    test_fraction=0.15,\n",
    "    custom_albumentation_transform=generate_transforms(),\n",
    "    batch_size=200,\n",
    "    num_workers=11,\n",
    ")\n",
    "\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/nas2/npower/miniconda3/envs/mphys-galaxy/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:168: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /share/nas2/npower/miniconda3/envs/mphys-galaxy/lib/ ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | loss_fn | CrossEntropyLoss | 0     \n",
      "1 | model   | ResNet           | 11.2 M\n",
      "---------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.712    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  21%|██        | 154/731 [02:25<09:04,  1.06it/s, v_num=2, train_loss_step=0.474, train_acc_step=0.050]"
     ]
    }
   ],
   "source": [
    "RUN_TEST = False\n",
    "\n",
    "model = ChiralityClassifier(\n",
    "    num_classes=3, #2 for Jia et al version\n",
    "    model_version=\"resnet18\",\n",
    "    optimizer=\"adamw\",\n",
    "    scheduler  =\"steplr\",\n",
    "    lr=0.0001,\n",
    "    weight_decay=0,\n",
    "    step_size=5,\n",
    "    gamma=0.85,\n",
    "    batch_size=60,\n",
    ")\n",
    "\n",
    "#stopping_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    max_epochs=60,\n",
    "    devices=1,\n",
    "    #callbacks=[stopping_callback]\n",
    ")\n",
    "\n",
    "#compiled_model = torch.compile(model, backend=\"eager\")\n",
    "\n",
    "trainer.fit(model,train_dataloaders=datamodule.train_dataloader(),val_dataloaders=datamodule.val_dataloader() )\n",
    "\n",
    "if RUN_TEST:\n",
    "    trainer.test(model,test_dataloader=datamodule.test_dataloader())\n",
    "    \n",
    "#torch.save(trainer.model.state_dict(), SAVE_PATH + \"/trained_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mphys-galaxy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

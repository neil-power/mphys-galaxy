{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Lightning for ResNet using galaxy_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from enum import Enum\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightning as pl\n",
    "import albumentations as A\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch import Tensor\n",
    "from torcheval.metrics import BinaryAccuracy\n",
    "from torchvision.models.resnet import BasicBlock, Bottleneck \n",
    "\n",
    "from galaxy_datasets.pytorch.galaxy_datamodule import GalaxyDataModule\n",
    "from typing import Any, Callable, List, Optional, Type, Union, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class class_mode(Enum):\n",
    "    S_or_Z = 0\n",
    "    S_or_Z_or_O = 1\n",
    "\n",
    "\n",
    "USE_GPU = True\n",
    "USE_DATA_SUBSET = False\n",
    "SAVE_PATH = \"../Models\"\n",
    "\n",
    "MODE = class_mode.S_or_Z_or_O\n",
    "\n",
    "#Number of CW, ACW and EL to select\n",
    "THRESHOLD = 0.8\n",
    "N_CW = 5000\n",
    "N_ACW = 5000\n",
    "N_EL = 5000\n",
    "\n",
    "IMG_SIZE = 160 # This is the output size of the generated image array\n",
    "\n",
    "if USE_DATA_SUBSET:\n",
    "    CATALOG_PATH = '../Data/subset_gz1_desi_cross_cat.csv'\n",
    "    DATA_PATH = '../Data/Subset'\n",
    "else:\n",
    "    CATALOG_PATH = '../Data/gz1_desi_cross_cat.csv'\n",
    "    DATA_PATH = '/share/nas2/walml/galaxy_zoo/decals/dr8/jpg'\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU cores available on device: 24\n",
      "NVIDIA A100-PCIE-40GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "#Run processes on CPU or GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"CPU cores available on device: {os.cpu_count()}\")\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of galaxies in GZ1 catalogue: 647837\n",
      "Very CW: 14243, Very ACW: 15420, Very EL: 143858\n",
      "Loaded 15000 galaxy images\n"
     ]
    }
   ],
   "source": [
    "catalog = pd.read_csv(CATALOG_PATH)\n",
    "very_CW_galaxies = catalog[catalog['P_CW']>THRESHOLD]\n",
    "very_ACW_galaxies = catalog[catalog['P_ACW']>THRESHOLD]\n",
    "very_EL_galaxies = catalog[catalog['P_EL']>THRESHOLD]\n",
    "print(f\"Number of galaxies in GZ1 catalogue: {catalog.shape[0]}\")\n",
    "print(f\"Very CW: {very_CW_galaxies.shape[0]}, Very ACW: {very_ACW_galaxies.shape[0]}, Very EL: {very_EL_galaxies.shape[0]}\")\n",
    "\n",
    "galaxy_subset = pd.concat([very_CW_galaxies[0:N_CW],very_ACW_galaxies[0:N_ACW],very_EL_galaxies[0:N_EL]])\n",
    "catalog = galaxy_subset.reset_index()\n",
    "\n",
    "\n",
    "if MODE == class_mode.S_or_Z:\n",
    "    #Select only S or Z \n",
    "    catalog = catalog[catalog['P_EL']<0.8]\n",
    "    #Select features (clockwise and anti-clockwise probabilities)\n",
    "    Y = catalog[['P_CW','P_ACW']]\n",
    "    classes = [r'P_CW',r'P_ACW']\n",
    "    num_classes = 2\n",
    "\n",
    "elif MODE == class_mode.S_or_Z_or_O:\n",
    "    #Select only S or Z or other\n",
    "    catalog['P_OTHER'] = catalog['P_EL']+catalog['P_EDGE']+catalog['P_DK']+catalog['P_MG']\n",
    "    Y = catalog[['P_CW','P_ACW','P_OTHER']]\n",
    "    classes = ['P_CW','P_ACW','P_OTHER']\n",
    "    num_classes = 3\n",
    "\n",
    "print(f\"Loaded {catalog.shape[0]} galaxy images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building file path list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 15000 galaxy filepaths\n"
     ]
    }
   ],
   "source": [
    "def get_file_paths(catalog_to_convert,folder_path ):\n",
    "    brick_ids = catalog_to_convert['dr8_id'].str.split(\"_\",expand=True)[0]\n",
    "    dr8_ids = catalog_to_convert['dr8_id']\n",
    "    file_locations = folder_path+'/'+brick_ids+'/'+dr8_ids+'.jpg'\n",
    "    print(f\"Created {file_locations.shape[0]} galaxy filepaths\")\n",
    "    return file_locations\n",
    "\n",
    "catalog['file_loc'] = get_file_paths(catalog,DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified Resnet50 based on Jia et al (2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JiaResnet(models.resnet.ResNet):\n",
    "    def __init__(self,\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\n",
    "        use_max_pool: bool = True,\n",
    "        use_avg_pool: bool = True,\n",
    "        avg_pool_size: Tuple[int] = (1, 1),\n",
    "        add_fc: Optional[List[int]] = None, *args, **kwargs):\n",
    "        \n",
    "        super().__init__(block, *args, **kwargs)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(avg_pool_size)\n",
    "        pool_expansion = 1\n",
    "        if not use_avg_pool:\n",
    "            pool_expansion = 16 if use_max_pool else 64\n",
    "        else:\n",
    "            pool_expansion = np.prod(avg_pool_size) \n",
    "\n",
    "        self.fc = self._make_fc(512 * block.expansion * pool_expansion, num_classes, add_fc)\n",
    "\n",
    "        self.use_max_pool = use_max_pool\n",
    "        self.use_avg_pool = use_avg_pool\n",
    "\n",
    "    def _make_fc(self, in_features: int, out_features: int, add_fc: Optional[List[int]]):\n",
    "        if add_fc is None:\n",
    "            return nn.Linear(in_features, out_features)\n",
    "        else:\n",
    "            add_fc.insert(0, in_features)\n",
    "            add_fc.append(out_features)\n",
    "            fc_layers = []\n",
    "            for i in range(len(add_fc) - 1):\n",
    "                fc_layers.append(nn.Linear(add_fc[i], add_fc[i + 1]))\n",
    "                if i != len(add_fc) - 2:\n",
    "                    fc_layers.append(nn.Tanh())\n",
    "            return nn.Sequential(*fc_layers)\n",
    "        \n",
    "    def _forward_impl(self, x: Tensor) -> Tensor: #Override forward\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        if self.use_max_pool:\n",
    "            x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if self.use_avg_pool:\n",
    "            x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x: Tensor) -> Tensor: #Override predict\n",
    "        x_i = torch.flip(x, (-1,))\n",
    "        a = self(x)\n",
    "        a_i = self(x_i)\n",
    "        return torch.cat((a[..., 0:1], a_i[..., 0:1], 0.5 * (a[..., 1:2] + a_i[..., 1:2])), dim=-1)\n",
    "\n",
    "\n",
    "def JiaResnet50(**kwargs: Any) -> JiaResnet:\n",
    "    model = JiaResnet(block=Bottleneck, layers=[3, 4, 6, 3], use_max_pool=True,\n",
    "     use_avg_pool=True, avg_pool_size=(1, 1), add_fc=[512, 512, 64, 64],**kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet classifier module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetClassifier(pl.LightningModule):\n",
    "    model_versions = {\n",
    "        \"resnet18\": models.resnet18,\n",
    "        \"resnet34\": models.resnet34,\n",
    "        \"resnet50\": models.resnet50,\n",
    "        \"resnet101\": models.resnet101,\n",
    "        \"resnet152\": models.resnet152,\n",
    "        \"jiaresnet50\": JiaResnet50\n",
    "    }\n",
    "    optimizers = {\"adamw\": optim.AdamW, \"sgd\": optim.SGD}\n",
    "    schedulers = {\"steplr\": optim.lr_scheduler.StepLR}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes,\n",
    "        model_version,\n",
    "        optimizer=\"adamw\",\n",
    "        scheduler  =\"steplr\",\n",
    "        lr=1e-3,\n",
    "        weight_decay=0,\n",
    "        step_size=5,\n",
    "        gamma=0.85,\n",
    "        batch_size=16\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.step_size = step_size\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = self.optimizers[optimizer]\n",
    "        self.scheduler = self.schedulers[scheduler]\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.acc = self.accuracy_metric #Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.model = self.model_versions[model_version](num_classes=num_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer_class = self.optimizer(self.parameters(), lr=self.lr,weight_decay=self.weight_decay)\n",
    "        scheduler = self.scheduler(optimizer_class, step_size=self.step_size, gamma=self.gamma)\n",
    "        return {\n",
    "        \"optimizer\": optimizer_class,\n",
    "        \"lr_scheduler\": {\"scheduler\": scheduler},\n",
    "        }\n",
    "\n",
    "    def _step(self, batch):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        loss = self.loss_fn(preds, y)\n",
    "        acc = self.acc(preds, y)\n",
    "        return loss, acc\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        #time here\n",
    "        loss, acc = self._step(batch)\n",
    "        # perform logging\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"train_acc\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, acc = self._step(batch)\n",
    "        # perform logging\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=False, logger=True)\n",
    "        self.log(\"val_acc\", acc, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, acc = self._step(batch)\n",
    "        # perform logging\n",
    "        self.log(\"test_loss\", loss, on_step=True, prog_bar=True, logger=True)\n",
    "        self.log(\"test_acc\", acc, on_step=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def accuracy_metric(self,predicted_labels,true_labels):\n",
    "        #Takes in softmaxed labels, checks if max column is the same\n",
    "\n",
    "        true_highest_prob = torch.argmax(true_labels, dim=1)\n",
    "        predicted_highest_prob = torch.argmax(predicted_labels, dim=1)   \n",
    "        \n",
    "        metric = BinaryAccuracy()\n",
    "        metric.update(predicted_highest_prob,true_highest_prob)\n",
    "        test_accuracy = metric.compute()\n",
    "        return test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transforms(resize_after_crop=IMG_SIZE):\n",
    "\n",
    "    transforms_to_apply = [\n",
    "        A.ToFloat(), #Converts from 0-255 to 0-1\n",
    "\n",
    "        A.Resize( #Resizes to\n",
    "            height=resize_after_crop,\n",
    "            width=resize_after_crop,\n",
    "            interpolation=1,\n",
    "            always_apply=True\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    return A.Compose(transforms_to_apply)\n",
    "\n",
    "datamodule = GalaxyDataModule(\n",
    "    label_cols=['P_CW','P_ACW','P_OTHER'],\n",
    "    catalog=catalog,\n",
    "    train_fraction=0.7,\n",
    "    val_fraction=0.15,\n",
    "    test_fraction=0.15,\n",
    "    custom_albumentation_transform=generate_transforms(),\n",
    "    batch_size=200,\n",
    "    num_workers=11,\n",
    "    #prefetch_factor=4,\n",
    ")\n",
    "\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/nas2/npower/miniconda3/envs/mphys-galaxy/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /share/nas2/npower/miniconda3/envs/mphys-galaxy/lib/ ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | loss_fn | CrossEntropyLoss | 0     \n",
      "1 | model   | JiaResnet        | 24.9 M\n",
      "---------------------------------------------\n",
      "24.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "24.9 M    Total params\n",
      "99.428    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 53/53 [01:01<00:00,  0.87it/s, v_num=13, train_loss_step=0.227, train_acc_step=0.640, val_acc=0.637, train_loss_epoch=0.232, train_acc_epoch=0.665]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 53/53 [01:04<00:00,  0.82it/s, v_num=13, train_loss_step=0.227, train_acc_step=0.640, val_acc=0.637, train_loss_epoch=0.232, train_acc_epoch=0.665]\n"
     ]
    }
   ],
   "source": [
    "RUN_TEST = False\n",
    "model = ResNetClassifier(\n",
    "    num_classes=2, #2 for Jia et al version\n",
    "    model_version=\"jiaresnet50\",\n",
    "    optimizer=\"adamw\",\n",
    "    scheduler  =\"steplr\",\n",
    "    lr=0.0001,\n",
    "    weight_decay=0,\n",
    "    step_size=5,\n",
    "    gamma=0.85,\n",
    "    batch_size=60,\n",
    ")\n",
    "\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "#stopping_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    max_epochs=50,\n",
    "    devices=1,\n",
    "    #callbacks=[stopping_callback]\n",
    ")\n",
    "\n",
    "trainer.fit(model,train_dataloaders=datamodule.train_dataloader(),val_dataloaders=datamodule.val_dataloader() )\n",
    "\n",
    "if RUN_TEST:\n",
    "    trainer.test(model,test_dataloader=datamodule.test_dataloader())\n",
    "    \n",
    "torch.save(trainer.model.state_dict(), SAVE_PATH + \"/trained_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mphys-galaxy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Lightning for ResNet using galaxy_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from enum import Enum\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import lightning as pl\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "import albumentations as A\n",
    "from galaxy_datasets.pytorch.galaxy_datamodule import GalaxyDataModule\n",
    "from ChiralityClassifier import ChiralityClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modes(Enum):\n",
    "    FULL_DATASET = 0 #Use all 600,000 galaxies\n",
    "    CUT_DATASET = 1 #Use cut of 200,000 galaxies\n",
    "    BEST_SUBSET = 2 #Select N best S,Z & other galaxies, evenly split\n",
    "    LOCAL_SUBSET = 3 #Use local cache of 1500 galaxies\n",
    "\n",
    "IMG_SIZE = 160 # This is the output size of the generated image array\n",
    "MODE = modes.LOCAL_SUBSET\n",
    "\n",
    "#If using best subset, Number of CW, ACW and EL to select\n",
    "THRESHOLD = 0.8\n",
    "N_CW = 5000\n",
    "N_ACW = 5000\n",
    "N_EL = 5000\n",
    "\n",
    "# FULL_CATALOG_PATH = '../Data/gz1_desi_cross_cat.csv'\n",
    "# FULL_DATA_PATH = '/share/nas2/walml/galaxy_zoo/decals/dr8/jpg'\n",
    "# CUT_CATALOG_PATH = '../Data/gz1_desi_cross_cat_cut.csv'\n",
    "# LOCAL_SUBSET_CATALOG_PATH = '../Data/subset_gz1_desi_cross_cat.csv'\n",
    "# LOCAL_SUBSET_DATA_PATH = '../Data/Subset'\n",
    "FULL_CATALOG_PATH = '/share/nas2/npower/mphys-galaxy/Data/gz1_desi_cross_cat.csv'\n",
    "FULL_DATA_PATH = '/share/nas2/walml/galaxy_zoo/decals/dr8/jpg'\n",
    "CUT_CATALOG_PATH = '/share/nas2/npower/mphys-galaxy/Data/gz1_desi_cross_cat_cut.csv'\n",
    "LOCAL_SUBSET_CATALOG_PATH = '/share/nas2/npower/mphys-galaxy/Data/subset_gz1_desi_cross_cat.csv'\n",
    "LOCAL_SUBSET_DATA_PATH = '/share/nas2/npower/mphys-galaxy/Data/Subset'\n",
    "SAVE_PATH = \"/share/nas2/npower/mphys-galaxy/Models\"\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pytorch 2.2.1\n",
      "CPU cores available on device: 24\n",
      "NVIDIA A100-PCIE-40GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "#Check GPU & Torch is working\n",
    "print(f\"Using pytorch {torch.__version__}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"CPU cores available on device: {os.cpu_count()}\")\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1500 galaxy filepaths\n"
     ]
    }
   ],
   "source": [
    "def get_file_paths(catalog_to_convert,folder_path):\n",
    "    brick_ids = catalog_to_convert['dr8_id'].str.split(\"_\",expand=True)[0]\n",
    "    dr8_ids = catalog_to_convert['dr8_id']\n",
    "    file_locations = folder_path+'/'+brick_ids+'/'+dr8_ids+'.jpg'\n",
    "    print(f\"Created {file_locations.shape[0]} galaxy filepaths\")\n",
    "    return file_locations\n",
    "\n",
    "if MODE == modes.FULL_DATASET:\n",
    "    catalog = pd.read_csv(FULL_CATALOG_PATH)\n",
    "    catalog['file_loc'] = get_file_paths(catalog,FULL_DATA_PATH)\n",
    "\n",
    "elif MODE == modes.CUT_DATASET:\n",
    "    catalog = pd.read_csv(CUT_CATALOG_PATH)\n",
    "    catalog['file_loc'] = get_file_paths(catalog,FULL_DATA_PATH)\n",
    "\n",
    "elif MODE == modes.BEST_SUBSET:\n",
    "    catalog = pd.read_csv(FULL_CATALOG_PATH)\n",
    "    very_CW_galaxies = catalog[catalog['P_CW']>THRESHOLD]\n",
    "    very_ACW_galaxies = catalog[catalog['P_ACW']>THRESHOLD]\n",
    "    very_EL_galaxies = catalog[catalog['P_EL']>THRESHOLD]\n",
    "    print(f\"Very CW: {very_CW_galaxies.shape[0]}, Very ACW: {very_ACW_galaxies.shape[0]}, Very EL: {very_EL_galaxies.shape[0]}\")\n",
    "\n",
    "    galaxy_subset = pd.concat([very_CW_galaxies[0:N_CW],very_ACW_galaxies[0:N_ACW],very_EL_galaxies[0:N_EL]])\n",
    "    catalog = galaxy_subset.reset_index()\n",
    "    catalog['file_loc'] = get_file_paths(catalog,FULL_DATA_PATH)\n",
    "\n",
    "elif MODE == modes.LOCAL_SUBSET:\n",
    "    catalog = pd.read_csv(LOCAL_SUBSET_CATALOG_PATH)\n",
    "    catalog['file_loc'] = get_file_paths(catalog,LOCAL_SUBSET_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging non-S/Z galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1500 galaxy images\n"
     ]
    }
   ],
   "source": [
    "catalog['P_OTHER'] = catalog['P_EL']+catalog['P_EDGE']+catalog['P_DK']+catalog['P_MG']\n",
    "print(f\"Loaded {catalog.shape[0]} galaxy images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transforms(resize_after_crop=IMG_SIZE):\n",
    "    transforms_to_apply = [\n",
    "        A.ToFloat(), #Converts from 0-255 to 0-1\n",
    "\n",
    "        A.Resize( #Resizes to 160x160\n",
    "            height=resize_after_crop,\n",
    "            width=resize_after_crop,\n",
    "            interpolation=1,\n",
    "            always_apply=True\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    return A.Compose(transforms_to_apply)\n",
    "\n",
    "datamodule = GalaxyDataModule(\n",
    "    label_cols=['P_CW','P_ACW','P_OTHER'],\n",
    "    catalog=catalog,\n",
    "    train_fraction=0.7,\n",
    "    val_fraction=0.15,\n",
    "    test_fraction=0.15,\n",
    "    custom_albumentation_transform=generate_transforms(),\n",
    "    batch_size=200,\n",
    "    num_workers=11,\n",
    ")\n",
    "\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/nas2/npower/miniconda3/envs/mphys-galaxy/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:168: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /share/nas2/npower/miniconda3/envs/mphys-galaxy/lib/ ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | loss_fn | CrossEntropyLoss | 0     \n",
      "1 | model   | ResNet           | 11.2 M\n",
      "---------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.712    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/nas2/npower/miniconda3/envs/mphys-galaxy/lib/python3.11/site-packages/lightning/pytorch/profilers/pytorch.py:429: UserWarning: The PyTorch Profiler default schedule will be overridden as there is not enough steps to properly record traces.\n",
      "  warning_cache.warn(\n",
      "STAGE:2024-03-05 11:27:53 35502:35502 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "/share/nas2/npower/miniconda3/envs/mphys-galaxy/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, v_num=108826, train_loss_step=0.229, train_acc_step=1.000, val_acc=0.724, train_loss_epoch=0.220, train_acc_epoch=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 6/6 [00:04<00:00,  1.36it/s, v_num=108826, train_loss_step=0.229, train_acc_step=1.000, val_acc=0.724, train_loss_epoch=0.220, train_acc_epoch=1.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-03-05 11:32:26 35502:35502 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-03-05 11:32:27 35502:35502 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "FIT Profiler Report\n",
      "Profile stats for: records\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*        25.97%       94.523s        74.54%      271.335s     562.935ms       0.000us         0.00%        6.205s      12.874ms           482  \n",
      "                        [pl][profile]run_training_epoch        -3.60%  -13120166.000us        49.71%      180.970s        3.016s       0.000us         0.00%       15.272s     254.539ms            60  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        41.67%      151.696s        41.68%      151.737s     315.461ms       0.000us         0.00%      10.007ms      20.805us           481  \n",
      "[pl][profile][Callback]ModelCheckpoint{'monitor': No...        23.68%       86.199s        24.59%       89.526s        1.492s       0.000us         0.00%        1.908s      31.808ms            60  \n",
      "[pl][profile][_TrainingEpochLoop].train_dataloader_n...         0.01%      39.825ms        22.92%       83.434s     231.761ms       0.000us         0.00%       4.244ms      11.789us           360  \n",
      "                [pl][profile][_EvaluationLoop].val_next         0.00%       7.477ms        18.78%       68.350s     564.877ms       0.000us         0.00%       5.763ms      47.628us           121  \n",
      "                        [pl][profile]run_training_batch         0.01%      41.563ms         4.61%       16.792s      46.643ms       0.000us         0.00%       10.766s      29.905ms           360  \n",
      "[pl][profile][LightningModule]ChiralityClassifier.op...         0.01%      24.838ms         4.59%       16.724s      46.455ms       0.000us         0.00%       10.766s      29.905ms           360  \n",
      "                              Optimizer.step#AdamW.step         2.39%        8.684s         4.59%       16.699s      46.386ms       0.000us         0.00%       10.766s      29.905ms           360  \n",
      "                                        cudaMemcpyAsync         2.65%        9.636s         2.65%        9.637s     437.116us     237.507ms         0.98%     238.931ms      10.837us         22047  \n",
      "    [pl][module]torchvision.models.resnet.ResNet: model         0.05%     194.213ms         2.48%        9.027s      18.767ms       0.000us         0.00%       12.660s      26.320ms           481  \n",
      "[pl][profile][Strategy]SingleDeviceStrategy.training...         0.09%     339.884ms         2.20%        8.014s      22.261ms       0.000us         0.00%       10.758s      29.882ms           360  \n",
      "[pl][profile][Callback]TQDMProgressBar.on_train_batc...         0.16%     583.533ms         2.03%        7.392s      20.534ms       0.000us         0.00%      26.973ms      74.925us           360  \n",
      "                                             aten::item         0.02%      67.567ms         1.91%        6.937s     146.805us       0.000us         0.00%      86.467ms       1.830us         47253  \n",
      "                              aten::_local_scalar_dense         0.01%      28.606ms         1.89%        6.869s     145.376us       4.273ms         0.02%      86.467ms       1.830us         47253  \n",
      "[pl][profile][Strategy]SingleDeviceStrategy.backward...         1.83%        6.648s         1.86%        6.757s      18.770ms       0.000us         0.00%       5.807ms      16.131us           360  \n",
      "autograd::engine::evaluate_function: ConvolutionBack...         0.04%     162.925ms         0.99%        3.590s     498.616us       0.000us         0.00%        7.842s       1.089ms          7200  \n",
      "                                   ConvolutionBackward0         0.01%      46.521ms         0.92%        3.341s     464.065us       0.000us         0.00%        7.549s       1.049ms          7200  \n",
      "                             aten::convolution_backward         0.43%        1.572s         0.91%        3.295s     457.604us        5.939s        24.49%        7.549s       1.049ms          7200  \n",
      "                                       cudaLaunchKernel         0.85%        3.089s         0.89%        3.254s      14.202us        2.467s        10.17%        2.467s      10.767us        229129  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 364.017s\n",
      "Self CUDA time total: 24.248s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RUN_TEST = False\n",
    "\n",
    "# Models:\n",
    "#resnet18,resnet34,resnet50,resnet101,resnet152,\n",
    "#jiaresnet50,LeNet,\n",
    "#G_ResNet18,G_LeNet,\n",
    "\n",
    "model = ChiralityClassifier(\n",
    "    num_classes=3, #2 for Jia et al version\n",
    "    model_version=\"resnet18\",\n",
    "    optimizer=\"adamw\",\n",
    "    scheduler  =\"steplr\",\n",
    "    lr=0.0001,\n",
    "    weight_decay=0,\n",
    "    step_size=5,\n",
    "    gamma=0.85,\n",
    "    batch_size=60,\n",
    ")\n",
    "\n",
    "#stopping_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    max_epochs=60,\n",
    "    devices=1,\n",
    "    default_root_dir=\"/share/nas2/npower/mphys-galaxy/Code/\",\n",
    "    profiler=\"pytorch\"\n",
    "    #callbacks=[stopping_callback]\n",
    ")\n",
    "\n",
    "#compiled_model = torch.compile(model, backend=\"eager\")\n",
    "trainer.fit(model,train_dataloaders=datamodule.train_dataloader(),val_dataloaders=datamodule.val_dataloader() )\n",
    "\n",
    "if RUN_TEST:\n",
    "    trainer.test(model,test_dataloader=datamodule.test_dataloader())\n",
    "    \n",
    "torch.save(trainer.model.state_dict(), SAVE_PATH + \"/test_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mphys-galaxy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

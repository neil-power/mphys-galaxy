{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pipeline\n",
    "This file contains all the data processing steps used to generate the training, validation and testing datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import shutil\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from torch.utils.data import random_split\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery.sdss import SDSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options \n",
    "Select any part of the data pipeline to redo, otherwise this notebook will run without saving or overwriting any files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGENERATE_MATCHED_CATALOG = False #Match GZ1 and DESI objects\n",
    "REGENERATE_QUERIED_CATALOG = False #Run SDSS query on matched catalog to return data and cut objects - VERY SLOW\n",
    "REGENERATE_LOCAL_SUBSET_CATALOG = False #Create balanced subset of 1500 best S/Z/El galaxies\n",
    "CREATE_LOCAL_SUBSET_COPY = False #Copy all galaxies in local subset to local folder\n",
    "REGENERATE_BEST_SUBSET_CATALOG = False #Create balanced catalog of 15000 best S/Z/El galaxies\n",
    "REGENERATE_CUT_CATALOG = False #Create catalog of matched galaxies after astro cuts\n",
    "REGENERATE_TEST_TRAIN_CATALOG = False #Create testing and training datasets from cut catalog\n",
    "REGENERATE_DOWNSAMPLED_CATALOG = False #Downsample training catalog to improve balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(catalog, cat_name):\n",
    "    total = catalog.shape[0]\n",
    "    largest_prob_class = catalog[['P_CW','P_ACW','P_OTHER']].idxmax(axis=1)\n",
    "    CW_galaxies = np.count_nonzero(largest_prob_class=='P_CW')\n",
    "    ACW_galaxies = np.count_nonzero(largest_prob_class=='P_ACW')\n",
    "    OTHER_galaxies = np.count_nonzero(largest_prob_class=='P_OTHER')\n",
    "    print(f\"{cat_name} contains {total} galaxies. CW: {CW_galaxies} ({CW_galaxies/total:.1%}), ACW: {ACW_galaxies} ({ACW_galaxies/total:.1%}), Other: {OTHER_galaxies} ({OTHER_galaxies/total:.1%})\")\n",
    "\n",
    "def create_balanced_subset(catalog, threshold, N_CW,N_ACW,N_EL):\n",
    "    very_CW_galaxies = catalog[catalog['P_CW']>threshold]\n",
    "    very_ACW_galaxies = catalog[catalog['P_ACW']>threshold]\n",
    "    very_EL_galaxies = catalog[catalog['P_EL']>threshold]\n",
    "    print(f\"Total Very CW: {very_CW_galaxies.shape[0]}, Very ACW: {very_ACW_galaxies.shape[0]}, Very EL: {very_EL_galaxies.shape[0]}\")\n",
    "\n",
    "    galaxy_subset = pd.concat([very_CW_galaxies[0:N_CW],very_ACW_galaxies[0:N_ACW],very_EL_galaxies[0:N_EL]])\n",
    "    galaxy_subset = galaxy_subset.reset_index()\n",
    "    print(f\"Number of galaxies in best subset catalog: {galaxy_subset.shape[0]}\")\n",
    "    galaxy_subset.loc[:,['P_OTHER']] = galaxy_subset[['P_EL','P_EDGE','P_DK','P_MG']].sum(axis=1).round(3)\n",
    "    galaxy_subset.reset_index()\n",
    "    return galaxy_subset\n",
    "\n",
    "def get_filepath_by_id(dr8_id,folder_path):\n",
    "    brick_id = dr8_id.split('_')[0]\n",
    "    file_loc = f\"{folder_path}/{brick_id}/{dr8_id}.jpg\"\n",
    "    return file_loc\n",
    "\n",
    "def split_dataframe(data, no_of_batches):\n",
    "    batch_size = math.ceil(data.shape[0] / no_of_batches)\n",
    "    batched_df = [data[i:i+batch_size] for i in range(0,data.shape[0], batch_size)]\n",
    "    return batched_df\n",
    "\n",
    "def get_SDSS_info_batch(catalog,save_path,radius = \"1 arcsec\",overwrite=True,batch_start=0):\n",
    "    batched_df = split_dataframe(catalog,200) #30s per batch, more than this seems to fail\n",
    "\n",
    "    if os.path.exists(save_path) and overwrite:\n",
    "        os.remove(save_path)\n",
    "\n",
    "    for i in range(batch_start, len(batched_df)):    \n",
    "        batch = batched_df[i]        \n",
    "        coords = SkyCoord(batch[\"RA\"],batch[\"DEC\"],unit=(u.hourangle, u.deg))\n",
    "        results = pd.DataFrame(SDSS.query_region(coords,data_release=7,radius=radius,photoobj_fields=[\"objID\",\"ra\",\"dec\",\"err_r\",\"petroR50_r\",\"petroR50Err_r\"]).to_pandas())\n",
    "    \n",
    "        #Clean up OBJID fields\n",
    "        batch.loc[:,'OBJID'] = batch['OBJID'].astype(str).str.strip()\n",
    "        results.loc[:,'objID'] = results['objID'].astype(str).str.strip()\n",
    "        \n",
    "        k=0\n",
    "        j=0\n",
    "        rows_list = []\n",
    "        while k < len(batch)-1: #Run through each item in batch\n",
    "            batch_row = batch.iloc[k]\n",
    "            results_row = results.iloc[j]\n",
    "            \n",
    "            if batch_row['OBJID'] == results_row['objID']: #If OBJIDs match\n",
    "                #print(f\"Match at row {k}\")\n",
    "                if batch.iloc[k+1]['OBJID'] == results.iloc[j+1]['objID']: #If next object OBJIDs match\n",
    "                    #print(f\"Adding row {k} as next row matches\")\n",
    "                    batch_dict = batch_row.to_dict()\n",
    "                    results_dict = results_row.to_dict()\n",
    "                    batch_dict.update(results_dict)# Add matching rows from batch and results\n",
    "                    rows_list.append(batch_dict)\n",
    "                else:\n",
    "                    #print(f\"Skipping row {k} as next row does not match\")\n",
    "                    while batch.iloc[k+1]['OBJID'] != results.iloc[j+1]['objID']:\n",
    "                        j += 1 # Move through results until match found\n",
    "            else:\n",
    "                #print(f\"Skipping row {k} as next row does not match\")\n",
    "                while batch.iloc[k+1]['OBJID'] != results.iloc[j+1]['objID']:\n",
    "                    j += 1 # Move through results until match found\n",
    "            k += 1 #Move on to next i\n",
    "            j += 1 # Move on to next j\n",
    "\n",
    "        final_columns = batch.columns.to_list()+results.columns.to_list()\n",
    "        final = pd.DataFrame(rows_list,columns= final_columns)\n",
    "        reduced = final.drop([\"Unnamed: 0\",\"objID\",\"ra\",\"dec\"],axis=1)\n",
    "        \n",
    "        time.sleep(1)\n",
    "        reduced.to_csv(save_path, mode='a', header=not os.path.exists(save_path),index=False)\n",
    "        print(f\"Processing batch {i} ({len(batch)} items, {len(results)} results found, cut to {len(reduced)}))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in SDSS and GZ1 catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESI catalog contains 8.7 million objects.\n",
      "GZ1 catalog contains 667944 galaxies. CW: 32102 (4.8%), ACW: 33795 (5.1%), Other: 602047 (90.1%)\n"
     ]
    }
   ],
   "source": [
    "DESI_CATALOG_PATH = '../../Data/DESI/gz_desi_deep_learning_catalog_friendly.parquet' #Available from https://doi.org/10.5281/zenodo.8360385\n",
    "GZ_CATALOG_PATH = '../../Data/GalaxyZoo1_DR_table2.csv' # Available from ui.adsabs.harvard.edu/abs/2011MNRAS.410..166L/abstract or https://data.galaxyzoo.org/\n",
    "\n",
    "gz_catalog = pd.read_csv(GZ_CATALOG_PATH)\n",
    "gz_catalog.loc[:,['P_OTHER']] = gz_catalog[['P_EL','P_EDGE','P_DK','P_MG']].sum(axis=1).round(3)\n",
    "\n",
    "print(f\"DESI catalog contains 8.7 million objects.\")\n",
    "get_metrics(gz_catalog,\"GZ1 catalog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Cross-matching DESI DR8 & GZ1 (SDSS DR7)\n",
    "DESI images are organised by dr8_id, whereas GZ1 uses SDSS OBJID. Use astropy to match objects across both catalogs & add a 'dr8_id' column to the GZ1 catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of galaxies in matched catalog: 647837, removed 20107\n",
      "Matched catalog contains 667944 galaxies. CW: 32102 (4.8%), ACW: 33795 (5.1%), Other: 602047 (90.1%)\n"
     ]
    }
   ],
   "source": [
    "MATCHED_CATALOG = '../../Data/gz1_desi_cross_cat.csv'\n",
    "\n",
    "if REGENERATE_MATCHED_CATALOG:\n",
    "    desi_data = pd.read_parquet(DESI_CATALOG_PATH).reset_index(drop=True)\n",
    "    gz1_data = pd.read_csv(GZ_CATALOG_PATH).reset_index(drop=True)\n",
    "    ra1 = gz1_data['RA'].to_numpy() #Convert to skycoords\n",
    "    dec1 = gz1_data['DEC'].to_numpy()\n",
    "    zoo_cat = SkyCoord(ra=ra1, dec=dec1, unit=(u.hourangle, u.deg))\n",
    "\n",
    "    ra2 = desi_data['ra'].to_numpy()\n",
    "    dec2 = desi_data['dec'].to_numpy()\n",
    "    desi_cat = SkyCoord(ra=ra2, dec=dec2, unit=u.deg)\n",
    "\n",
    "    idx, d2d, d3d = zoo_cat.match_to_catalog_sky(desi_cat) #idx is index in desi_cat closest to zoo_cat\n",
    "    max_sep = 10 * u.arcsec\n",
    "    sep_constraint = d2d < max_sep\n",
    "    print(str(sep_constraint.sum()) + \" matches found\")\n",
    "\n",
    "    zoo_match = gz1_data[sep_constraint] #zoo df that has matches \n",
    "    desi_match = desi_data.loc[idx[sep_constraint]]\n",
    "    #get dr8 id from desi stack to zoo\n",
    "    desi_match_sort = desi_match.sort_index()\n",
    "    zoo_match_sort = zoo_match.set_index(idx[sep_constraint]).sort_index()\n",
    "    matched_catalog = pd.concat([zoo_match_sort, desi_match_sort['dr8_id']], axis=1).reset_index(drop=True)\n",
    "    matched_catalog.to_csv(MATCHED_CATALOG)\n",
    "\n",
    "matched_catalog = pd.read_csv(MATCHED_CATALOG)\n",
    "matched_catalog.loc[:,['P_OTHER']] = matched_catalog[['P_EL','P_EDGE','P_DK','P_MG']].sum(axis=1).round(3)\n",
    "print(f\"Number of galaxies in matched catalog: {matched_catalog.shape[0]}, removed {gz_catalog.shape[0]-matched_catalog.shape[0]}\")\n",
    "get_metrics(gz_catalog,\"Matched catalog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1a: Creating balanced local subset of 1500 most S, Z and El images for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local subset catalog contains 1500 galaxies. CW: 241 (16.1%), ACW: 251 (16.7%), Other: 1008 (67.2%)\n"
     ]
    }
   ],
   "source": [
    "LOCAL_SUBSET_CATALOG_PATH = '../../Data/gz1_desi_cross_cat_local_subset.csv'\n",
    "DESI_DATA_PATH = '/share/nas2/walml/galaxy_zoo/decals/dr8/jpg'\n",
    "SUBSET_DATA_PATH = '../../Data/Subset'\n",
    "\n",
    "if REGENERATE_LOCAL_SUBSET_CATALOG:\n",
    "    #local_subset_catalog = local_subset_catalog = local_subset_catalog.loc[:, ~local_subset_catalog.columns.str.contains('^Unnamed')]\n",
    "    local_subset_catalog = create_balanced_subset(matched_catalog, threshold=0.8, N_CW=500,N_ACW=500,N_EL=500)\n",
    "    local_subset_catalog.loc[:,['P_OTHER']] = matched_catalog[['P_EL','P_EDGE','P_DK','P_MG']].sum(axis=1).round(3)\n",
    "    local_subset_catalog.to_csv(LOCAL_SUBSET_CATALOG_PATH,index=False)\n",
    "\n",
    "local_subset_catalog = pd.read_csv(LOCAL_SUBSET_CATALOG_PATH)\n",
    "local_subset_catalog.loc[:,['P_OTHER']] = matched_catalog[['P_EL','P_EDGE','P_DK','P_MG']].sum(axis=1).round(3)\n",
    "\n",
    "if CREATE_LOCAL_SUBSET_COPY:\n",
    "    for index, galaxy in local_subset_catalog.iterrows():\n",
    "        g_dr8_id = galaxy['dr8_id']\n",
    "        galaxy_path = get_filepath_by_id(g_dr8_id,DESI_DATA_PATH) #ORIGINAL\n",
    "        new_path = get_filepath_by_id(g_dr8_id,SUBSET_DATA_PATH) #NEW\n",
    "\n",
    "        #MAKE FOLDER IN NEW\n",
    "        os.makedirs(os.path.dirname(new_path), exist_ok=True)\n",
    "        shutil.copy(galaxy_path, new_path) #COPY\n",
    "        \n",
    "get_metrics(local_subset_catalog,\"Local subset catalog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1b: Create balanced subset catalog of 15000 most S, Z & El galaxies for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best subset catalog contains 15000 galaxies. CW: 2418 (16.1%), ACW: 2479 (16.5%), Other: 10103 (67.4%)\n"
     ]
    }
   ],
   "source": [
    "BEST_SUBSET_CATALOG_PATH = '../../Data/gz1_desi_cross_cat_best_subset.csv'\n",
    "\n",
    "if REGENERATE_BEST_SUBSET_CATALOG:\n",
    "    best_subset_catalog = create_balanced_subset(matched_catalog, threshold=0.8, N_CW=5000,N_ACW=5000,N_EL=5000)\n",
    "    best_subset_catalog.loc[:,['P_OTHER']] = matched_catalog[['P_EL','P_EDGE','P_DK','P_MG']].sum(axis=1).round(3)\n",
    "    best_subset_catalog.to_csv(BEST_SUBSET_CATALOG_PATH,index=False)\n",
    "\n",
    "best_subset_catalog = pd.read_csv(BEST_SUBSET_CATALOG_PATH)\n",
    "best_subset_catalog.loc[:,['P_OTHER']] = matched_catalog[['P_EL','P_EDGE','P_DK','P_MG']].sum(axis=1).round(3)\n",
    "get_metrics(best_subset_catalog,\"Best subset catalog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Cut objects that have another object within 1 arcsec\n",
    "Query SDSS via astroquery to get r-band values, and cut objects that have another object within 1 arcsec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of galaxies with no objects within 1 arcsec: 213744, removed 434093\n",
      "Queried catalog contains 213744 galaxies. CW: 8688 (4.1%), ACW: 9190 (4.3%), Other: 195866 (91.6%)\n"
     ]
    }
   ],
   "source": [
    "QUERIED_CATALOG_PATH = '../../Data/gz1_desi_cross_cat_queried.csv'\n",
    "\n",
    "if REGENERATE_QUERIED_CATALOG:\n",
    "    get_SDSS_info_batch(matched_catalog,QUERIED_CATALOG_PATH)\n",
    "\n",
    "queried_catalog = pd.read_csv(QUERIED_CATALOG_PATH)\n",
    "queried_catalog.loc[:,['P_OTHER']] = queried_catalog[['P_EL','P_EDGE','P_DK','P_MG']].sum(axis=1).round(3)\n",
    "print(f\"Number of galaxies with no objects within 1 arcsec: {queried_catalog.shape[0]}, removed {matched_catalog.shape[0]-queried_catalog.shape[0]}\")\n",
    "get_metrics(queried_catalog,\"Queried catalog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Cut objects using magnitude/r-band\n",
    "\n",
    "Apply the following cuts\n",
    "-  r-band magnitude error >0 & <1\n",
    "- r-band half-light radius r50 >1 arcsec\n",
    "- relative r-band half-light radius error >0 & <0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of galaxies with r-band magnitude error >0 & <1: 213744, removed 0\n",
      "Number of galaxies with r-band half-light radius r50 >1 arcsec: 213369, removed 375\n",
      "Number of galaxies with relative r-band half-light radius error >0 & <0.25: 208682, removed 4687\n",
      "Jia et al (2023) Final Number: 173097. Difference: -35585\n",
      "Cut catalog contains 208682 galaxies. CW: 8520 (4.1%), ACW: 9023 (4.3%), Other: 191139 (91.6%)\n"
     ]
    }
   ],
   "source": [
    "CUT_CATALOG_PATH = '../../Data/gz1_desi_cross_cat_cut.csv'\n",
    "Jia_final = 173097\n",
    "\n",
    "reduced = queried_catalog[np.logical_and(queried_catalog[\"err_r\"]>0,queried_catalog[\"err_r\"]<1)]\n",
    "print(f\"Number of galaxies with r-band magnitude error >0 & <1: {reduced.shape[0]}, removed {queried_catalog.shape[0]-reduced.shape[0]}\")\n",
    "\n",
    "reduced2 = reduced[reduced[\"petroR50_r\"]>1]\n",
    "print(f\"Number of galaxies with r-band half-light radius r50 >1 arcsec: {reduced2.shape[0]}, removed {reduced.shape[0]-reduced2.shape[0]}\")\n",
    "\n",
    "r_band_err = reduced2[\"petroR50Err_r\"]/reduced2[\"petroR50_r\"]\n",
    "cut_catalog = reduced2[np.logical_and(r_band_err>0,r_band_err<0.25)]\n",
    "print(f\"Number of galaxies with relative r-band half-light radius error >0 & <0.25: {cut_catalog.shape[0]}, removed {reduced2.shape[0]-cut_catalog.shape[0]}\")\n",
    "\n",
    "print(f\"Jia et al (2023) Final Number: {Jia_final}. Difference: {Jia_final-cut_catalog.shape[0]}\")\n",
    "\n",
    "if REGENERATE_CUT_CATALOG:\n",
    "    cut_catalog.to_csv(CUT_CATALOG_PATH)\n",
    "\n",
    "get_metrics(cut_catalog,\"Cut catalog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Select testing dataset\n",
    "\n",
    "Select 15% of the cut data for a reserved test set, and, with a set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut catalog contains 208682 galaxies. CW: 8520 (4.1%), ACW: 9023 (4.3%), Other: 191139 (91.6%)\n",
      "Testing catalog contains 41737 galaxies. CW: 1682 (4.0%), ACW: 1840 (4.4%), Other: 38215 (91.6%)\n",
      "Training & validation catalog contains 166945 galaxies. CW: 6838 (4.1%), ACW: 7183 (4.3%), Other: 152924 (91.6%)\n"
     ]
    }
   ],
   "source": [
    "TESTING_CATALOG_PATH = '../../Data/gz1_desi_cross_cat_testing.csv'\n",
    "TRAIN_VAL_CATALOG_PATH = '../../Data/gz1_desi_cross_cat_train_val.csv'\n",
    "get_metrics(cut_catalog,\"Cut catalog\")\n",
    "generator1 = torch.Generator().manual_seed(42)\n",
    "testing_catalog, train_val_catalog = random_split(cut_catalog, [0.20,0.80], generator=generator1)\n",
    "#Convert from subsets\n",
    "testing_catalog = testing_catalog.dataset.iloc[testing_catalog.indices]\n",
    "train_val_catalog = train_val_catalog.dataset.iloc[train_val_catalog.indices]\n",
    "get_metrics(testing_catalog,\"Testing catalog\")\n",
    "get_metrics(train_val_catalog,\"Training & validation catalog\")\n",
    "\n",
    "if REGENERATE_TEST_TRAIN_CATALOG:\n",
    "    #Probably can drop unneeded columns\n",
    "    testing_catalog.to_csv(TESTING_CATALOG_PATH,index=False)\n",
    "    train_val_catalog.to_csv(TRAIN_VAL_CATALOG_PATH,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Downsampling\n",
    "\n",
    "From the training and validation catalog, keep \n",
    "- 1 in 20 galaxies with 0 < max(P_CW, P_ACW) <= 0.1\n",
    "- 1 in 5 galaxies with 0.1 < max(P_CW, P_ACW) <= 0.2 \n",
    "- 1 in 2 galaxies with 0.2 < max(P_CW, P_ACW) <= 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training & validation catalog contains 166945 galaxies. CW: 6838 (4.1%), ACW: 7183 (4.3%), Other: 152924 (91.6%)\n",
      "Downsampled catalog contains 35988 galaxies. CW: 6838 (19.0%), ACW: 7183 (20.0%), Other: 21967 (61.0%)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_VAL_DOWNSAMPLE_CATALOG_PATH = '../../Data/gz1_desi_cross_cat_train_val_downsample.csv'\n",
    "\n",
    "get_metrics(train_val_catalog,\"Training & validation catalog\")\n",
    "\n",
    "def cut_by_factor(cat,factor):\n",
    "    generator1 = torch.Generator().manual_seed(42)\n",
    "    kept_downsample, _ = random_split(cat, [1/factor,1-(1/factor)], generator=generator1)\n",
    "    return kept_downsample.dataset.iloc[kept_downsample.indices]\n",
    "\n",
    "sample_mask_1 = np.logical_and(train_val_catalog[['P_CW',\"P_ACW\"]].max(axis=1) >= 0, train_val_catalog[['P_CW',\"P_ACW\"]].max(axis=1) <= 0.1)\n",
    "sample_mask_2 = np.logical_and(train_val_catalog[['P_CW',\"P_ACW\"]].max(axis=1) > 0.1, train_val_catalog[['P_CW',\"P_ACW\"]].max(axis=1) <= 0.2)\n",
    "sample_mask_3 = np.logical_and(train_val_catalog[['P_CW',\"P_ACW\"]].max(axis=1) > 0.2, train_val_catalog[['P_CW',\"P_ACW\"]].max(axis=1) <= 0.3)\n",
    "keep_mask = np.logical_and(train_val_catalog[['P_CW',\"P_ACW\"]].max(axis=1) > 0.3, train_val_catalog[['P_CW',\"P_ACW\"]].max(axis=1) <= 1)\n",
    "\n",
    "kept_galaxies = train_val_catalog[keep_mask]\n",
    "downsample_set_1 = cut_by_factor(train_val_catalog[sample_mask_1],20)\n",
    "downsample_set_2 = cut_by_factor(train_val_catalog[sample_mask_2],5)\n",
    "downsample_set_3 = cut_by_factor(train_val_catalog[sample_mask_3],2)\n",
    "\n",
    "train_val_downsample_catalog = pd.concat([kept_galaxies,downsample_set_1,downsample_set_2,downsample_set_3])\n",
    "\n",
    "if REGENERATE_DOWNSAMPLED_CATALOG:\n",
    "    train_val_downsample_catalog.to_csv(TRAIN_VAL_DOWNSAMPLE_CATALOG_PATH)\n",
    "\n",
    "get_metrics(train_val_downsample_catalog,\"Downsampled catalog\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of all steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load initial GZ1 catalog\n",
      "GZ1 catalog contains 667944 galaxies. CW: 32102 (4.8%), ACW: 33795 (5.1%), Other: 602047 (90.1%)\n",
      "\n",
      "Step 1: Cross-match with DESI image catalog\n",
      "Matched catalog contains 647837 galaxies. CW: 31594 (4.9%), ACW: 33241 (5.1%), Other: 583002 (90.0%)\n",
      "\n",
      "Step 2: Cut objects that have another object within 1 arcsec by querying SDSS\n",
      "Queried catalog contains 213744 galaxies. CW: 8688 (4.1%), ACW: 9190 (4.3%), Other: 195866 (91.6%)\n",
      "\n",
      "Step 3: Cut objects using magnitude/r-band\n",
      "Cut catalog contains 208682 galaxies. CW: 8520 (4.1%), ACW: 9023 (4.3%), Other: 191139 (91.6%)\n",
      "\n",
      "Step 4: Select testing dataset\n",
      "Testing catalog contains 41737 galaxies. CW: 1682 (4.0%), ACW: 1840 (4.4%), Other: 38215 (91.6%)\n",
      "Train/val catalog contains 166945 galaxies. CW: 6838 (4.1%), ACW: 7183 (4.3%), Other: 152924 (91.6%)\n",
      "\n",
      "Step 5: Downsampling\n",
      "Downsampled train/val Catalog contains 35988 galaxies. CW: 6838 (19.0%), ACW: 7183 (20.0%), Other: 21967 (61.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Load initial GZ1 catalog\")\n",
    "get_metrics(gz_catalog,\"GZ1 catalog\")\n",
    "print(\"\\nStep 1: Cross-match with DESI image catalog\")\n",
    "get_metrics(matched_catalog,\"Matched catalog\")\n",
    "print(\"\\nStep 2: Cut objects that have another object within 1 arcsec by querying SDSS\")\n",
    "get_metrics(queried_catalog,\"Queried catalog\")\n",
    "print(\"\\nStep 3: Cut objects using magnitude/r-band\")\n",
    "get_metrics(cut_catalog,\"Cut catalog\")\n",
    "print(\"\\nStep 4: Select testing dataset\")\n",
    "get_metrics(testing_catalog,\"Testing catalog\")\n",
    "get_metrics(train_val_catalog,\"Train/val catalog\")\n",
    "print(\"\\nStep 5: Downsampling\")\n",
    "get_metrics(train_val_downsample_catalog,\"Downsampled train/val Catalog\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mphys-galaxy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

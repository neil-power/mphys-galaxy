{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_from_logger_paths(input_path,output_path):\n",
    "    metrics = pd.read_csv(input_path) #Only works for train logs currently\n",
    "    metrics = metrics.drop(['train_loss_step',\t'train_acc_step',\t'train_calibration_error_step'],axis=1)\n",
    "    metrics = metrics.groupby(metrics['epoch']).first()\n",
    "    #create_folder(output_path)\n",
    "    metrics.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard_reducer.event_loader import EventAccumulator\n",
    "import pandas as pd\n",
    "\n",
    "def save_metrics_from_tensorboard_paths(input_path,output_path):\n",
    "    accumulator = EventAccumulator(input_path).Reload()\n",
    "    metrics = pd.DataFrame()\n",
    "    #chose tags we want - epoch.unique, val_loss val_acc ,train_loss_epoch ,train_acc_epoch 60 \n",
    "    print(accumulator.scalar_tags)\n",
    "    epochs = pd.DataFrame(accumulator.Scalars('epoch')).set_index(\"step\").drop(columns=\"wall_time\").drop_duplicates(keep='last').rename(columns={'value': 'epoch'})\n",
    "    columns = []\n",
    "    labels = ['val_loss', 'val_acc', 'calibration_error', 'train_loss_epoch', 'train_acc_epoch', 'calibration_error_epoch', 'test_loss', 'test_acc']\n",
    "    labels = ['val_loss', 'val_acc', 'train_loss_epoch', 'train_acc_epoch']\n",
    "    for label in labels:\n",
    "        columns.append(pd.DataFrame(accumulator.Scalars(label)).set_index(\"step\").drop(columns=\"wall_time\").rename(columns={'value': label}))\n",
    "    metrics = epochs.join(columns)\n",
    "    metrics.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_loss_step', 'train_acc_step', 'epoch', 'val_loss', 'val_acc', 'train_loss_epoch', 'train_acc_epoch']\n"
     ]
    }
   ],
   "source": [
    "create_folder(\"..\\\\Metrics\\\\resnet18_best_subset\\\\version_0\")\n",
    "save_metrics_from_tensorboard_paths(\"lightning_logs\\\\resnet_18_best_subset\",\n",
    "                                    \"..\\\\Metrics\\\\resnet18_best_subset\\\\version_0\\\\train_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_metrics_from_logger_paths(\"lightning_logs\\\\resnet18_cut_dataset\\\\version_0\\\\metrics.csv\",\n",
    "                               \"..\\\\Metrics\\\\resnet18_cut_dataset\\\\version_0\\\\train_metrics.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mphys-galaxy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

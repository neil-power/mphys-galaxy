{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E2CNN example function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from escnn import gspaces\n",
    "import torch.nn as nn\n",
    "import escnn.nn as enn\n",
    "from torch import Tensor\n",
    "from typing import Type, Any, Callable, Union, List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 45 deg rotational model\n",
    "class C8SteerableCNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes=10):\n",
    "        \n",
    "        super(C8SteerableCNN, self).__init__()\n",
    "        \n",
    "        # the model is equivariant under rotations by 45 degrees, modelled by C8\n",
    "        self.r2_act = gspaces.rot2dOnR2(N=8)\n",
    "        \n",
    "        # the input image is a scalar field, corresponding to the trivial representation\n",
    "        in_type = enn.FieldType(self.r2_act, [self.r2_act.trivial_repr])\n",
    "        \n",
    "        # we store the input type for wrapping the images into a geometric tensor during the forward pass\n",
    "        self.input_type = in_type\n",
    "        \n",
    "        # convolution 1\n",
    "        # first specify the output type of the convolutional layer\n",
    "        # we choose 24 feature fields, each transforming under the regular representation of C8\n",
    "        out_type = enn.FieldType(self.r2_act, 24*[self.r2_act.regular_repr])\n",
    "        self.block1 = enn.SequentialModule(\n",
    "            enn.MaskModule(in_type, 29, margin=1),\n",
    "            enn.R2Conv(in_type, out_type, kernel_size=7, padding=1, bias=False),\n",
    "            enn.InnerBatchNorm(out_type),\n",
    "            enn.ReLU(out_type, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # convolution 2\n",
    "        # the old output type is the input type to the next layer\n",
    "        in_type = self.block1.out_type\n",
    "        # the output type of the second convolution layer are 48 regular feature fields of C8\n",
    "        out_type = enn.FieldType(self.r2_act, 48*[self.r2_act.regular_repr])\n",
    "        self.block2 = enn.SequentialModule(\n",
    "            enn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
    "            enn.InnerBatchNorm(out_type),\n",
    "            enn.ReLU(out_type, inplace=True)\n",
    "        )\n",
    "        self.pool1 = enn.SequentialModule(\n",
    "            enn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2)\n",
    "        )\n",
    "        \n",
    "        # convolution 3\n",
    "        # the old output type is the input type to the next layer\n",
    "        in_type = self.block2.out_type\n",
    "        # the output type of the third convolution layer are 48 regular feature fields of C8\n",
    "        out_type = enn.FieldType(self.r2_act, 48*[self.r2_act.regular_repr])\n",
    "        self.block3 = enn.SequentialModule(\n",
    "            enn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
    "            enn.InnerBatchNorm(out_type),\n",
    "            enn.ReLU(out_type, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # convolution 4\n",
    "        # the old output type is the input type to the next layer\n",
    "        in_type = self.block3.out_type\n",
    "        # the output type of the fourth convolution layer are 96 regular feature fields of C8\n",
    "        out_type = enn.FieldType(self.r2_act, 96*[self.r2_act.regular_repr])\n",
    "        self.block4 = enn.SequentialModule(\n",
    "            enn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
    "            enn.InnerBatchNorm(out_type),\n",
    "            enn.ReLU(out_type, inplace=True)\n",
    "        )\n",
    "        self.pool2 = enn.SequentialModule(\n",
    "            enn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2)\n",
    "        )\n",
    "        \n",
    "        # convolution 5\n",
    "        # the old output type is the input type to the next layer\n",
    "        in_type = self.block4.out_type\n",
    "        # the output type of the fifth convolution layer are 96 regular feature fields of C8\n",
    "        out_type = enn.FieldType(self.r2_act, 96*[self.r2_act.regular_repr])\n",
    "        self.block5 = enn.SequentialModule(\n",
    "            enn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
    "            enn.InnerBatchNorm(out_type),\n",
    "            enn.ReLU(out_type, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # convolution 6\n",
    "        # the old output type is the input type to the next layer\n",
    "        in_type = self.block5.out_type\n",
    "        # the output type of the sixth convolution layer are 64 regular feature fields of C8\n",
    "        out_type = enn.FieldType(self.r2_act, 64*[self.r2_act.regular_repr])\n",
    "        self.block6 = enn.SequentialModule(\n",
    "            enn.R2Conv(in_type, out_type, kernel_size=5, padding=1, bias=False),\n",
    "            enn.InnerBatchNorm(out_type),\n",
    "            enn.ReLU(out_type, inplace=True)\n",
    "        )\n",
    "        self.pool3 = enn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=1, padding=0)\n",
    "        \n",
    "        self.gpool = enn.GroupPooling(out_type)\n",
    "        \n",
    "        # number of output channels\n",
    "        c = self.gpool.out_type.size\n",
    "        \n",
    "        # Fully Connected\n",
    "        self.fully_net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(c, 64),\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.ELU(inplace=True),\n",
    "            torch.nn.Linear(64, n_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, input: torch.Tensor):\n",
    "        # wrap the input tensor in a GeometricTensor\n",
    "        # (associate it with the input type)\n",
    "        x = enn.GeometricTensor(input, self.input_type)\n",
    "        \n",
    "        # apply each equivariant block\n",
    "        \n",
    "        # Each layer has an input and an output type\n",
    "        # A layer takes a GeometricTensor in input.\n",
    "        # This tensor needs to be associated with the same representation of the layer's input type\n",
    "        #\n",
    "        # The Layer outputs a new GeometricTensor, associated with the layer's output type.\n",
    "        # As a result, consecutive layers need to have matching input/output types\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        \n",
    "        # pool over the spatial dimensions\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        # pool over the group\n",
    "        x = self.gpool(x)\n",
    "\n",
    "        # unwrap the output GeometricTensor\n",
    "        # (take the Pytorch tensor and discard the associated representation)\n",
    "        x = x.tensor\n",
    "        \n",
    "        # classify with the final fully connected layers)\n",
    "        x = self.fully_net(x.reshape(x.shape[0], -1))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiii = C8SteerableCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change from planes to plane type probably needed?\n",
    "def conv3x3(in_type: enn.FieldType, out_type: enn.FieldType, stride=1, padding=1,\n",
    "            dilation=1, bias=False):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return enn.R2Conv(in_type, out_type, 3,\n",
    "                      stride=stride,\n",
    "                      padding=padding,\n",
    "                      dilation=dilation,\n",
    "                      bias=bias,\n",
    "                      #sigma=None,\n",
    "                      #frequencies_cutoff=lambda r: 3*r,\n",
    "                      )\n",
    "\n",
    "\n",
    "def conv1x1(in_type: enn.FieldType, out_type: enn.FieldType, stride=1, padding=0,\n",
    "            dilation=1, bias=False):\n",
    "    \"\"\"1x1 convolution with padding\"\"\"\n",
    "    return enn.R2Conv(in_type, out_type, 1,\n",
    "                      stride=stride,\n",
    "                      padding=padding,\n",
    "                      dilation=dilation,\n",
    "                      bias=bias,\n",
    "                      #sigma=None,\n",
    "                      #frequencies_cutoff=lambda r: 3*r,\n",
    "                      )\n",
    "\n",
    "\n",
    "class BasicBlock(enn.EquivariantModule):\n",
    "    expansion: int = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        #inplanes: int,\n",
    "        in_type: enn.FieldType, #\n",
    "        #planes: int,\n",
    "        inner_type: enn.FieldType, #\n",
    "        out_type: enn.FieldType=None, #\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[torch.nn.Module] = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., torch.nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if out_type is None: #\n",
    "            out_type = in_type #\n",
    "\n",
    "        #self.in_type = in_type\n",
    "        #inner_type = inner_type\n",
    "        #self.out_type = out_type\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(in_type, inner_type, stride)\n",
    "        self.bn1 = enn.InnerBatchNorm(inner_type)\n",
    "        self.relu = nn.ReLU(inner_type, inplace=True) #nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(inner_type, inner_type)\n",
    "        self.bn2 = enn.InnerBatchNorm(inner_type)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(torch.nn.Module):\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
    "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
    "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
    "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
    "\n",
    "    expansion: int = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: enn.FieldType,\n",
    "        planes: enn.FieldType,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[torch.nn.Module] = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., torch.nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups # not gonna like this\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = enn.ReLU(planes, inplace=True) #nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'escnn.nn' has no attribute 'Module'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mResNet\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m      5\u001b[0m         block: Type[Union[BasicBlock, Bottleneck]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m         norm_layer: Optional[Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, nn\u001b[38;5;241m.\u001b[39mModule]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28msuper\u001b[39m(ResNet, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "Cell \u001b[1;32mIn[9], line 17\u001b[0m, in \u001b[0;36mResNet\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mResNet\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m      5\u001b[0m         block: Type[Union[BasicBlock, Bottleneck]],\n\u001b[0;32m      6\u001b[0m         layers: List[\u001b[38;5;28mint\u001b[39m],\n\u001b[0;32m      7\u001b[0m         num_channels: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m      8\u001b[0m         num_classes: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m,\n\u001b[0;32m      9\u001b[0m         use_max_pool: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     10\u001b[0m         use_avg_pool: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m         avg_pool_size: Tuple[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m),\n\u001b[0;32m     12\u001b[0m         add_fc: Optional[List[\u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     13\u001b[0m         zero_init_residual: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     14\u001b[0m         groups: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     15\u001b[0m         width_per_group: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m,\n\u001b[0;32m     16\u001b[0m         replace_stride_with_dilation: Optional[List[\u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m---> 17\u001b[0m         norm_layer: Optional[Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, nn\u001b[38;5;241m.\u001b[39mModule]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28msuper\u001b[39m(ResNet, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m norm_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'escnn.nn' has no attribute 'Module'"
     ]
    }
   ],
   "source": [
    "class ResNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\n",
    "        layers: List[int],\n",
    "        num_channels: int = 3,\n",
    "        num_classes: int = 1000,\n",
    "        use_max_pool: bool = False,\n",
    "        use_avg_pool: bool = True,\n",
    "        avg_pool_size: Tuple[int] = (4, 4),\n",
    "        add_fc: Optional[List[int]] = None,\n",
    "        zero_init_residual: bool = False,\n",
    "        groups: int = 1,\n",
    "        width_per_group: int = 64,\n",
    "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "        norm_layer: Optional[Callable[..., torch.nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = torch.nn.BatchNorm2d ########\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64 ######\n",
    "        self.dilation = 1 \n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(num_channels, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(avg_pool_size)\n",
    "        pool_expansion = 1\n",
    "        if not use_avg_pool:\n",
    "            pool_expansion = 16 if use_max_pool else 64\n",
    "        else:\n",
    "            pool_expansion = np.prod(avg_pool_size)\n",
    "        self.fc = self._make_fc(512 * block.expansion * pool_expansion, num_classes, add_fc)\n",
    "\n",
    "        self.use_max_pool = use_max_pool\n",
    "        self.use_avg_pool = use_avg_pool\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_fc(in_features: int, out_features: int, add_fc: Optional[List[int]]):\n",
    "        if add_fc is None:\n",
    "            return nn.Linear(in_features, out_features)\n",
    "        else:\n",
    "            add_fc.insert(0, in_features)\n",
    "            add_fc.append(out_features)\n",
    "            fc_layers = []\n",
    "            for i in range(len(add_fc) - 1):\n",
    "                fc_layers.append(nn.Linear(add_fc[i], add_fc[i + 1]))\n",
    "                if i != len(add_fc) - 2:\n",
    "                    fc_layers.append(nn.Tanh())\n",
    "            return nn.Sequential(*fc_layers)\n",
    "\n",
    "    def _make_layer(self, block: Type[Union[BasicBlock, Bottleneck]], planes: int, blocks: int,\n",
    "                    stride: int = 1, dilate: bool = False) -> nn.Sequential:\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        if self.use_max_pool:\n",
    "            x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if self.use_avg_pool:\n",
    "            x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "    def predict(self, x: Tensor) -> Tensor:\n",
    "        x_i = torch.flip(x, (-1,))\n",
    "        a = self(x)\n",
    "        a_i = self(x_i)\n",
    "        return torch.cat((a[..., 0:1], a_i[..., 0:1], 0.5 * (a[..., 1:2] + a_i[..., 1:2])), dim=-1)\n",
    "\n",
    "def _resnet(\n",
    "    arch: str,\n",
    "    block: Type[Union[BasicBlock, Bottleneck]],\n",
    "    layers: List[int],\n",
    "    pretrained: bool,\n",
    "    progress: bool,\n",
    "    **kwargs: Any\n",
    ") -> ResNet:\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        raise NotImplementedError\n",
    "        \"\"\"state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\"\"\"\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Galaxy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

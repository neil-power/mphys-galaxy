{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetClassifier(pl.LightningModule):\n",
    "    resnets = {\n",
    "        18: models.resnet18,\n",
    "        34: models.resnet34,\n",
    "        50: models.resnet50,\n",
    "        101: models.resnet101,\n",
    "        152: models.resnet152,\n",
    "    }\n",
    "    optimizers = {\"adam\": Adam, \"sgd\": SGD}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes,\n",
    "        resnet_version,\n",
    "        train_path,\n",
    "        val_path,\n",
    "        test_path=None,\n",
    "        optimizer=\"adam\",\n",
    "        lr=1e-3,\n",
    "        batch_size=16,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.train_path = train_path\n",
    "        self.val_path = val_path\n",
    "        self.test_path = test_path\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = self.optimizers[optimizer]\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.acc = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.resnet_model = self.resnets[resnet_version]\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.resnet_model(X)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def _step(self, batch):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        \n",
    "        loss = self.loss_fn(preds, y)\n",
    "        acc = self.acc(preds, y)\n",
    "        return loss, acc\n",
    "\n",
    "    def _dataloader(self, data_path, shuffle=False):\n",
    "        # values here are specific to pneumonia dataset and should be updated for custom data\n",
    "        transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((500, 500)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.48232,), (0.23051,)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        img_folder = ImageFolder(data_path, transform=transform)\n",
    "\n",
    "        return DataLoader(img_folder, batch_size=self.batch_size, shuffle=shuffle)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self._dataloader(self.train_path, shuffle=True)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc = self._step(batch)\n",
    "        # perform logging\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"train_acc\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self._dataloader(self.val_path)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, acc = self._step(batch)\n",
    "        # perform logging\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=False, logger=True)\n",
    "        self.log(\"val_acc\", acc, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self._dataloader(self.test_path)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, acc = self._step(batch)\n",
    "        # perform logging\n",
    "        self.log(\"test_loss\", loss, on_step=True, prog_bar=True, logger=True)\n",
    "        self.log(\"test_acc\", acc, on_step=True, prog_bar=True, logger=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_TEST = False #Run trained model on test dataset\n",
    "\n",
    "model = ResNetClassifier(\n",
    "    num_classes=3,\n",
    "    resnet_version=50,\n",
    "    train_path=args.train_set,\n",
    "    val_path=args.val_set,\n",
    "    test_path=args.test_set,\n",
    "    optimizer=\"adam\",\n",
    "    lr=0.0001,\n",
    "    batch_size=60,\n",
    ")\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath=save_path,\n",
    "    filename=\"resnet-model-{epoch}-{val_loss:.2f}-{val_acc:0.2f}\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_top_k=3,\n",
    "    mode=\"min\",\n",
    "    save_last=True,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    max_epochs=\"80\",\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "\n",
    "save_path = \"./models\"\n",
    "\n",
    "stopping_callback = pl.callbacks.EarlyStopping()\n",
    "\n",
    "trainer.fit(model)\n",
    "\n",
    "if RUN_TEST:\n",
    "    trainer.test(model)\n",
    "    \n",
    "torch.save(trainer.model.resnet_model.state_dict(), save_path + \"/trained_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mphys-galaxy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

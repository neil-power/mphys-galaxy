{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of Pytorch Lightning for ResNet using galaxy_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightning as pl\n",
    "import albumentations as A\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torcheval.metrics import BinaryAccuracy\n",
    "\n",
    "from galaxy_datasets.pytorch.galaxy_datamodule import GalaxyDataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class class_mode(Enum):\n",
    "    S_or_Z = 0\n",
    "    S_or_Z_or_O = 1\n",
    "\n",
    "\n",
    "USE_GPU = True\n",
    "USE_DATA_SUBSET = False\n",
    "SAVE_PATH = \"../Models\"\n",
    "\n",
    "MODE = class_mode.S_or_Z_or_O\n",
    "\n",
    "#Number of CW, ACW and EL to select\n",
    "THRESHOLD = 0.8\n",
    "N_CW = 5000\n",
    "N_ACW = 5000\n",
    "N_EL = 5000\n",
    "\n",
    "IMG_SIZE = 160 # This is the output size of the generated image array\n",
    "\n",
    "if USE_DATA_SUBSET:\n",
    "    CATALOG_PATH = '../Data/subset_gz1_desi_cross_cat.csv'\n",
    "    DATA_PATH = '../Data/Subset'\n",
    "else:\n",
    "    CATALOG_PATH = '../Data/gz1_desi_cross_cat.csv'\n",
    "    DATA_PATH = '/share/nas2/walml/galaxy_zoo/decals/dr8/jpg'\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA A100-PCIE-40GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "#Run processes on CPU or GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of galaxies in GZ1 catalogue: 647837\n",
      "Very CW: 14243, Very ACW: 15420, Very EL: 143858\n",
      "Loaded 15000 galaxy images\n"
     ]
    }
   ],
   "source": [
    "catalog = pd.read_csv(CATALOG_PATH)\n",
    "very_CW_galaxies = catalog[catalog['P_CW']>THRESHOLD]\n",
    "very_ACW_galaxies = catalog[catalog['P_ACW']>THRESHOLD]\n",
    "very_EL_galaxies = catalog[catalog['P_EL']>THRESHOLD]\n",
    "print(f\"Number of galaxies in GZ1 catalogue: {catalog.shape[0]}\")\n",
    "print(f\"Very CW: {very_CW_galaxies.shape[0]}, Very ACW: {very_ACW_galaxies.shape[0]}, Very EL: {very_EL_galaxies.shape[0]}\")\n",
    "\n",
    "galaxy_subset = pd.concat([very_CW_galaxies[0:N_CW],very_ACW_galaxies[0:N_ACW],very_EL_galaxies[0:N_EL]])\n",
    "catalog = galaxy_subset.reset_index()\n",
    "\n",
    "\n",
    "if MODE == class_mode.S_or_Z:\n",
    "    #Select only S or Z \n",
    "    catalog = catalog[catalog['P_EL']<0.8]\n",
    "    #Select features (clockwise and anti-clockwise probabilities)\n",
    "    Y = catalog[['P_CW','P_ACW']]\n",
    "    classes = [r'P_CW',r'P_ACW']\n",
    "    num_classes = 2\n",
    "\n",
    "elif MODE == class_mode.S_or_Z_or_O:\n",
    "    #Select only S or Z or other\n",
    "    catalog['P_OTHER'] = catalog['P_EL']+catalog['P_EDGE']+catalog['P_DK']+catalog['P_MG']\n",
    "    Y = catalog[['P_CW','P_ACW','P_OTHER']]\n",
    "    classes = ['P_CW','P_ACW','P_OTHER']\n",
    "    num_classes = 3\n",
    "\n",
    "print(f\"Loaded {catalog.shape[0]} galaxy images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building file path list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 15000 galaxy filepaths\n"
     ]
    }
   ],
   "source": [
    "def get_file_paths(catalog_to_convert,folder_path ):\n",
    "    brick_ids = catalog_to_convert['dr8_id'].str.split(\"_\",expand=True)[0]\n",
    "    dr8_ids = catalog_to_convert['dr8_id']\n",
    "    file_locations = folder_path+'/'+brick_ids+'/'+dr8_ids+'.jpg'\n",
    "    print(f\"Created {file_locations.shape[0]} galaxy filepaths\")\n",
    "    return file_locations\n",
    "\n",
    "catalog['file_loc'] = get_file_paths(catalog,DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet classifier module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetClassifier(pl.LightningModule):\n",
    "    resnets = {\n",
    "        18: models.resnet18,\n",
    "        34: models.resnet34,\n",
    "        50: models.resnet50,\n",
    "        101: models.resnet101,\n",
    "        152: models.resnet152,\n",
    "    }\n",
    "    optimizers = {\"adamw\": optim.AdamW, \"sgd\": optim.SGD}\n",
    "    schedulers = {\"steplr\": optim.lr_scheduler.StepLR}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes,\n",
    "        resnet_version,\n",
    "        optimizer=\"adamw\",\n",
    "        scheduler  =\"steplr\",\n",
    "        lr=1e-3,\n",
    "        weight_decay=0,\n",
    "        step_size=5,\n",
    "        gamma=0.85,\n",
    "        batch_size=16\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.step_size = step_size\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = self.optimizers[optimizer]\n",
    "        self.scheduler = self.schedulers[scheduler]\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.acc = self.accuracy_metric #Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.model = self.resnets[resnet_version](num_classes=num_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer_class = self.optimizer(self.parameters(), lr=self.lr,weight_decay=self.weight_decay)\n",
    "        scheduler = self.scheduler(optimizer_class, step_size=self.step_size, gamma=self.gamma)\n",
    "        return {\n",
    "        \"optimizer\": optimizer_class,\n",
    "        \"lr_scheduler\": {\"scheduler\": scheduler},\n",
    "        }\n",
    "\n",
    "    def _step(self, batch):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        loss = self.loss_fn(preds, y)\n",
    "        acc = self.acc(preds, y)\n",
    "        return loss, acc\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        #time here\n",
    "        loss, acc = self._step(batch)\n",
    "        # perform logging\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"train_acc\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, acc = self._step(batch)\n",
    "        # perform logging\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=False, logger=True)\n",
    "        self.log(\"val_acc\", acc, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, acc = self._step(batch)\n",
    "        # perform logging\n",
    "        self.log(\"test_loss\", loss, on_step=True, prog_bar=True, logger=True)\n",
    "        self.log(\"test_acc\", acc, on_step=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def accuracy_metric(self,predicted_labels,true_labels):\n",
    "        #Takes in softmaxed labels, checks if max column is the same\n",
    "\n",
    "        true_highest_prob = torch.argmax(true_labels, dim=1)\n",
    "        predicted_highest_prob = torch.argmax(predicted_labels, dim=1)   \n",
    "        \n",
    "        metric = BinaryAccuracy()\n",
    "        metric.update(predicted_highest_prob,true_highest_prob)\n",
    "        test_accuracy = metric.compute()\n",
    "        return test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transforms(crop_scale_bounds=(0.7, 0.8),\n",
    "    crop_ratio_bounds=(0.9, 1.1),\n",
    "    resize_after_crop=IMG_SIZE):\n",
    "\n",
    "    transforms_to_apply = [\n",
    "        A.ToFloat(), #Converts from 0-255 to 0-1\n",
    "\n",
    "        A.RandomResizedCrop(\n",
    "            height=resize_after_crop,  # after crop resize\n",
    "            width=resize_after_crop,\n",
    "            scale=crop_scale_bounds,  # crop factor\n",
    "            ratio=crop_ratio_bounds,  # crop aspect ratio\n",
    "            interpolation=1,  # This is \"INTER_LINEAR\" == BILINEAR interpolation. See: https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html\n",
    "            always_apply=True\n",
    "        ),  # new aspect ratio\n",
    "        \n",
    "        #A.VerticalFlip(p=0.5),\n",
    "        #A.Rotate(limit=180, interpolation=1,\n",
    "        #            always_apply=True, border_mode=0, value=0),\n",
    "    ]\n",
    "\n",
    "    return A.Compose(transforms_to_apply)\n",
    "\n",
    "datamodule = GalaxyDataModule(\n",
    "    label_cols=['P_CW','P_ACW','P_OTHER'],\n",
    "    catalog=catalog,\n",
    "    train_fraction=0.7,\n",
    "    val_fraction=0.15,\n",
    "    test_fraction=0.15,\n",
    "    custom_albumentation_transform=generate_transforms(),\n",
    "    batch_size=200,  # careful - will affect final performance\n",
    "    num_workers=7,\n",
    "    #prefetch_factor=4,\n",
    ")\n",
    "\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(datamodule.train_dataloader().dataset[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/nas2/npower/miniconda3/envs/mphys-galaxy/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /share/nas2/npower/miniconda3/envs/mphys-galaxy/lib/ ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | loss_fn | CrossEntropyLoss | 0     \n",
      "1 | model   | ResNet           | 11.2 M\n",
      "---------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.712    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 53/53 [00:44<00:00,  1.20it/s, v_num=11, train_loss_step=0.251, train_acc_step=0.670, val_acc=0.644, train_loss_epoch=0.250, train_acc_epoch=0.664]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 53/53 [00:44<00:00,  1.19it/s, v_num=11, train_loss_step=0.251, train_acc_step=0.670, val_acc=0.644, train_loss_epoch=0.250, train_acc_epoch=0.664]\n"
     ]
    }
   ],
   "source": [
    "RUN_TEST = False #Run trained model on test dataset\n",
    "\n",
    "model = ResNetClassifier(\n",
    "    num_classes=3,\n",
    "    resnet_version=18,\n",
    "    optimizer=\"adamw\",\n",
    "    scheduler  =\"steplr\",\n",
    "    lr=0.0001,\n",
    "    weight_decay=0,\n",
    "    step_size=5,\n",
    "    gamma=0.85,\n",
    "    batch_size=60,\n",
    ")\n",
    "\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "#stopping_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    max_epochs=50,\n",
    "    devices=1,\n",
    "    #callbacks=[stopping_callback]\n",
    ")\n",
    "\n",
    "trainer.fit(model,train_dataloaders=datamodule.train_dataloader(),val_dataloaders=datamodule.val_dataloader() )\n",
    "\n",
    "if RUN_TEST:\n",
    "    trainer.test(model,test_dataloader=datamodule.test_dataloader())\n",
    "    \n",
    "torch.save(trainer.model.state_dict(), SAVE_PATH + \"/trained_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mphys-galaxy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ezzy\\miniconda3\\envs\\Galaxy\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib as plt\n",
    "from torch import Tensor\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "import os\n",
    "#from .resnet import *\n",
    "import numpy as np\n",
    "from typing import Type, Any, Callable, Union, List, Optional, Tuple\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset,Subset\n",
    "from torchvision.models import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_USE = False\n",
    "USE_GPU = False\n",
    "early_stopping = False\n",
    "QUIET =False\n",
    "SUBSET = True\n",
    "\n",
    "#model_parameters={}\n",
    "#model_parameters['resnet50'] = ([64,128,256,512],[3,4,6,3],4,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "#run processes on CPU or GPU\n",
    "if USE_GPU:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if device.type == 'cuda':\n",
    "        print(torch.cuda.get_device_name(0))\n",
    "        print('Memory Usage:')\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths(catalog_to_convert,folder_path ):\n",
    "    brick_ids = catalog_to_convert['dr8_id'].str.split(\"_\",expand=True)[0]\n",
    "    dr8_ids = catalog_to_convert['dr8_id']\n",
    "    file_locations = folder_path+'/'+brick_ids+'/'+dr8_ids+'.jpg'\n",
    "    return file_locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull cross_cat with labels\n",
    "if SUBSET:\n",
    "    data_file = '../Data/subset_gz1_desi_cross_cat.csv'\n",
    "else:\n",
    "    data_file = '../Data/gz1_desi_cross_cat.csv'\n",
    "cross_cat = pd.read_csv(data_file)\n",
    "Y = cross_cat[['P_CW','P_ACW']]#[['P_EL','P_CW','P_ACW']]\n",
    "classes = [r'P_CW',r'P_ACW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ../Data/Subset/265946/265946_2961.jpg\n",
       "1    ../Data/Subset/265992/265992_3062.jpg\n",
       "2    ../Data/Subset/267371/267371_3388.jpg\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_locations = get_file_paths(cross_cat,'../Data/Subset')\n",
    "file_locations.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image processing func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR = True\n",
    "RAW_SIZE = 15\n",
    "IMG_SIZE = 160\n",
    "\n",
    "TARGET_SIZE = 5\n",
    "TRANSLATE = 0.\n",
    "ROTATE = False\n",
    "FLIP = False\n",
    "LABEL = 2\n",
    "SHUFFLE = False\n",
    "\n",
    "\n",
    "def img_proc(img, raw_size=RAW_SIZE, target_size=TARGET_SIZE, translate=TRANSLATE, rotate=ROTATE,\n",
    "             random_generator=None):\n",
    "    assert img.shape[-2] == img.shape[-1]\n",
    "    assert translate >= 0\n",
    "    if random_generator is None:\n",
    "        random_generator = int.from_bytes(os.urandom(4), byteorder='little')\n",
    "    rng = np.random.default_rng(random_generator)\n",
    "\n",
    "    if not isinstance(target_size, (float, int)):\n",
    "        target_size = rng.uniform(*target_size)\n",
    "    if rotate:\n",
    "        assert target_size * (1 + translate) * 2**0.5 < raw_size\n",
    "        if isinstance(rotate, bool):\n",
    "            rotate = rng.uniform(0., 360.)\n",
    "        img = ndimage.rotate(img, rotate, axes=(-1, -2), reshape=False, order=1)\n",
    "    else:\n",
    "        assert target_size * (1 + translate) < raw_size\n",
    "    s = img.shape[-1]\n",
    "    translate = translate * target_size\n",
    "    t_x = rng.uniform(-translate, translate) if translate > 0 else 0\n",
    "    t_y = rng.uniform(-translate, translate) if translate > 0 else 0\n",
    "    a = int(s * (raw_size - target_size + t_x) / (2 * raw_size))\n",
    "    b = int(s * (raw_size - target_size + t_y) / (2 * raw_size))\n",
    "    c = int(s * target_size / raw_size)\n",
    "    return img[..., a:(a + c), b:(b + c)]\n",
    "\n",
    "\n",
    "def read_img(path, color=COLOR, img_size=IMG_SIZE, atleast_3d=True, random_flip=FLIP,\n",
    "             shuffle_channel=SHUFFLE, random_generator=None, **kwargs):\n",
    "    if random_generator is None:\n",
    "        random_generator = int.from_bytes(os.urandom(4), byteorder='little')\n",
    "    rng = np.random.default_rng(random_generator)\n",
    "\n",
    "    jpeg_file = (np.asarray(Image.open(path)) / 255).astype(np.float32)\n",
    "    if color:\n",
    "        img = np.moveaxis(jpeg_file, -1, 0)\n",
    "        if shuffle_channel:\n",
    "            if isinstance(shuffle_channel, bool):\n",
    "                shuffle_channel = rng.permutation(img.shape[0])\n",
    "            img = img[shuffle_channel]\n",
    "    else:\n",
    "        img = np.mean(jpeg_file, axis=-1)\n",
    "    img = img_proc(img, random_generator=rng, **kwargs)\n",
    "    rng.uniform(size=100) # just to jump the rng\n",
    "\n",
    "    if img_size is not None:\n",
    "        z = img_size / img.shape[-1]\n",
    "        if img.ndim == 2:\n",
    "            img = ndimage.zoom(img, (z, z), order=1)\n",
    "            if atleast_3d:\n",
    "                img = img[np.newaxis]\n",
    "        elif img.ndim == 3:\n",
    "            img = ndimage.zoom(img, (1, z, z), order=1)\n",
    "        else:\n",
    "            raise RuntimeError\n",
    "\n",
    "    if random_flip:\n",
    "        flip = int(rng.integers(0, 2, 1))\n",
    "        flip = 2 * flip - 1\n",
    "    else:\n",
    "        flip = 1\n",
    "    return np.ascontiguousarray(img[..., ::flip])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 160, 160)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_img(file_locations[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.empty(0, 3, 160,160)\n",
    "for i in range(len(file_locations)):\n",
    "    X = torch.cat((X, torch.from_numpy(read_img(file_locations[i])).float()[np.newaxis]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1500, 3, 160, 160])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnetX = (Num of channels, repetition, Bottleneck_expansion , Bottleneck_layer)\n",
    "#model_parameters['resnet50'] = ([64,128,256,512],[3,4,6,3],4,True)\n",
    "imp_model = resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\n",
    "           'wide_resnet50_2', 'wide_resnet101_2']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
    "    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n",
    "    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n",
    "    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n",
    "}\n",
    "\n",
    "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion: int = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
    "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
    "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
    "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
    "\n",
    "    expansion: int = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\n",
    "        layers: List[int],\n",
    "        num_channels: int = 3,\n",
    "        num_classes: int = 1000,\n",
    "        use_max_pool: bool = False,\n",
    "        use_avg_pool: bool = True,\n",
    "        avg_pool_size: Tuple[int] = (4, 4),\n",
    "        add_fc: Optional[List[int]] = None,\n",
    "        zero_init_residual: bool = False,\n",
    "        groups: int = 1,\n",
    "        width_per_group: int = 64,\n",
    "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(num_channels, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(avg_pool_size)\n",
    "        pool_expansion = 1\n",
    "        if not use_avg_pool:\n",
    "            pool_expansion = 16 if use_max_pool else 64\n",
    "        else:\n",
    "            pool_expansion = np.prod(avg_pool_size)\n",
    "        self.fc = self._make_fc(512 * block.expansion * pool_expansion, num_classes, add_fc)\n",
    "\n",
    "        self.use_max_pool = use_max_pool\n",
    "        self.use_avg_pool = use_avg_pool\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_fc(in_features: int, out_features: int, add_fc: Optional[List[int]]):\n",
    "        if add_fc is None:\n",
    "            return nn.Linear(in_features, out_features)\n",
    "        else:\n",
    "            add_fc.insert(0, in_features)\n",
    "            add_fc.append(out_features)\n",
    "            fc_layers = []\n",
    "            for i in range(len(add_fc) - 1):\n",
    "                fc_layers.append(nn.Linear(add_fc[i], add_fc[i + 1]))\n",
    "                if i != len(add_fc) - 2:\n",
    "                    fc_layers.append(nn.Tanh())\n",
    "            return nn.Sequential(*fc_layers)\n",
    "\n",
    "    def _make_layer(self, block: Type[Union[BasicBlock, Bottleneck]], planes: int, blocks: int,\n",
    "                    stride: int = 1, dilate: bool = False) -> nn.Sequential:\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        if self.use_max_pool:\n",
    "            x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if self.use_avg_pool:\n",
    "            x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "    def predict(self, x: Tensor) -> Tensor:\n",
    "        x_i = torch.flip(x, (-1,))\n",
    "        a = self(x)\n",
    "        a_i = self(x_i)\n",
    "        return torch.cat((a[..., 0:1], a_i[..., 0:1], 0.5 * (a[..., 1:2] + a_i[..., 1:2])), dim=-1)\n",
    "\n",
    "\n",
    "def _resnet(\n",
    "    arch: str,\n",
    "    block: Type[Union[BasicBlock, Bottleneck]],\n",
    "    layers: List[int],\n",
    "    pretrained: bool,\n",
    "    progress: bool,\n",
    "    **kwargs: Any\n",
    ") -> ResNet:\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        raise NotImplementedError\n",
    "        \"\"\"state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\"\"\"\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
    "    r\"\"\"ResNet-50 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,\n",
    "                   **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZSClassifier - this is just a specific resnet and can't be trained well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZSClassifier(ResNet):\n",
    "    \"\"\"\n",
    "    Finding Z-like (clockwise) and S-like (anticlockwise) spiral galaxies.\n",
    "    \"\"\"\n",
    "    def __init__(self): #state_dict=ZS_DICT,\n",
    "        model='resnet50'\n",
    "        device='cpu' #str(device)\n",
    "\n",
    "        if not model == 'resnet50':\n",
    "            raise NotImplementedError\n",
    "        if isinstance(model, str):\n",
    "            model = eval(model)\n",
    "        self.model = model(num_channels=3, num_classes=2, use_max_pool=True, use_avg_pool=True,\n",
    "                           avg_pool_size=(1, 1), add_fc=[512, 512, 64, 64])\n",
    "        if device == 'cuda':\n",
    "            device = torch.device(device)\n",
    "            #self.model.load_state_dict(torch.load(state_dict))\n",
    "            self.model.to(device)\n",
    "        elif device == 'cpu':\n",
    "            device = torch.device(device)\n",
    "            #self.model.load_state_dict(torch.load(state_dict, map_location=device))\n",
    "        self.eval()\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.model.predict(*args, **kwargs)\n",
    "\n",
    "    def eval(self, *args, **kwargs):\n",
    "        return self.model.eval(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classifier setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hii = ZSClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters for the NN\n",
    "#input_size = idk\n",
    "#hidden_size = 20#32\n",
    "learning_rate = 0.0001\n",
    "weight_decay = 1\n",
    "\n",
    "num_epochs = 120\n",
    "batch_size = 60 #60\n",
    "\n",
    "modfile = 'resnet50modfile.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to train the model on data\n",
    "def train(model, trainloader, optimiser, device):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, labels) in enumerate(trainloader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        #calculate train loss\n",
    "        p_y = model(data)\n",
    "        loss_criterion = nn.CrossEntropyLoss()\n",
    "        #labels = labels.type(torch.LongTensor) \n",
    "        labels = labels.softmax(dim=1).to(device)\n",
    "        loss = loss_criterion(p_y, labels)\n",
    "            \n",
    "        train_loss += loss.item() * data.size(0)\n",
    "\n",
    "        #feed the loss back\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "    train_loss /= len(trainloader.dataset)\n",
    "    return train_loss\n",
    "\n",
    "#function to test the model on data\n",
    "def validate(model, testloader, device):\n",
    "    test_loss = 0.0\n",
    "    mse_loss = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, labels) in enumerate(testloader):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            #calculate test loss\n",
    "            p_y = model(data)\n",
    "            loss_criterion = nn.CrossEntropyLoss()\n",
    "            labels = labels.softmax(dim=1).to(device)\n",
    "            loss = loss_criterion(p_y, labels)\n",
    "            mse_criterion = nn.MSELoss()\n",
    "            mse = mse_criterion(p_y, labels)\n",
    "\n",
    "            mse_loss += mse.item() * data.size(0)\n",
    "            test_loss += loss.item() * data.size(0)\n",
    "            \n",
    "        test_loss /= len(testloader.dataset)\n",
    "        test_loss /= len(testloader.dataset)\n",
    "\n",
    "    return test_loss, mse_loss\n",
    "\n",
    "def data_split(frac_val, data):\n",
    "    dataset_size = len(data)\n",
    "    nval = int(frac_val*dataset_size)\n",
    "\n",
    "    indices = list(range(dataset_size))\n",
    "    train_indices, val_indices = indices[nval:], indices[:nval]\n",
    "\n",
    "    train_sampler = Subset(data, train_indices)\n",
    "    valid_sampler = Subset(data, val_indices)\n",
    "    test_loader=() #blank if not used\n",
    "\n",
    "    if TEST_USE:\n",
    "        nval2 = int(0.5*dataset_size)\n",
    "        indices = list(range(valid_sampler))\n",
    "        test_indices, val_indices = indices[nval2:], indices[:nval2]\n",
    "\n",
    "        test_sampler = Subset(data, test_indices)\n",
    "        valid_sampler = Subset(data, val_indices)\n",
    "        test_loader = torch.utils.data.DataLoader(test_sampler, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_sampler, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(valid_sampler, batch_size=batch_size, shuffle=True)\n",
    "    return train_loader, val_loader ,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to run the entire model train/test loop\n",
    "def run_func(X,Y):\n",
    "    X_tensor = X\n",
    "    Y_tensor = torch.from_numpy(Y.values).float()\n",
    "\n",
    "    dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "    train_loader,val_loader, test_loader = data_split(0.7,dataset)\n",
    "\n",
    "    #create the model\n",
    "    #model = ZSClassifier()\n",
    "    model = resnet50(num_channels=3, num_classes=2, use_max_pool=True, use_avg_pool=True,\n",
    "                           avg_pool_size=(1, 1), add_fc=[512, 512, 64, 64])\n",
    "    \n",
    "    #optimizer and learning rate scheduler\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay = weight_decay)#0.005, #0.01\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.85)\n",
    "\n",
    "    #array to store metrics\n",
    "    result_arr = np.zeros((num_epochs,4))\n",
    "\n",
    "    _bestloss = 1.\n",
    "    #NN learning\n",
    "    for epoch in range(num_epochs):\n",
    "    \n",
    "        train_loss = train(model, train_loader, optimizer, device)\n",
    "        val_loss, mse_loss = validate(model, val_loader, device)\n",
    "        \n",
    "        #scheduler.step()\n",
    "\n",
    "        if early_stopping and val_loss<_bestloss:\n",
    "            _bestloss = val_loss\n",
    "            torch.save(model.state_dict(), modfile)\n",
    "            best_epoch = epoch\n",
    "\n",
    "        #set output row\n",
    "        results = [epoch, train_loss, val_loss, mse_loss]\n",
    "        result_arr[epoch] = results\n",
    "\n",
    "        #print epocch results\n",
    "        if not QUIET:\n",
    "            print('Epoch: {}, Train Loss: {:4f}, Validation Loss: {:4f}, MSE Loss: {:4f}'.format(epoch, train_loss, val_loss, mse_loss))\n",
    "            print('Current learning rate is: {}'.format(optimizer.param_groups[0]['lr']))\n",
    "    \n",
    "    test_arr=[]\n",
    "    if TEST_USE:\n",
    "        #Test data run\n",
    "        bestmodel=resnet50(num_channels=3, num_classes=2, use_max_pool=True, use_avg_pool=True,\n",
    "                           avg_pool_size=(1, 1), add_fc=[512, 512, 64, 64]).to(device)\n",
    "        bestmodel.load_state_dict(torch.load('modfile.pt'))\n",
    "        test_loss, mse_loss = validate(bestmodel, test_loader, device)\n",
    "        test_arr=[test_loss, mse_loss]\n",
    "\n",
    "    if not early_stopping:\n",
    "        torch.save(model.state_dict(), modfile)\n",
    "        best_epoch = -1\n",
    "\n",
    "    return result_arr, test_arr, best_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 0.698129, Validation Loss: 0.000660, MSE Loss: 240.112358\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 1, Train Loss: 0.694135, Validation Loss: 0.000660, MSE Loss: 246.478722\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 2, Train Loss: 0.693493, Validation Loss: 0.000660, MSE Loss: 235.075819\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 3, Train Loss: 0.693270, Validation Loss: 0.000660, MSE Loss: 241.472294\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 4, Train Loss: 0.693182, Validation Loss: 0.000660, MSE Loss: 245.825264\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 5, Train Loss: 0.693159, Validation Loss: 0.000660, MSE Loss: 246.897254\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 6, Train Loss: 0.693147, Validation Loss: 0.000660, MSE Loss: 243.403127\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 7, Train Loss: 0.693140, Validation Loss: 0.000660, MSE Loss: 244.526911\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 8, Train Loss: 0.693138, Validation Loss: 0.000660, MSE Loss: 246.264628\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 9, Train Loss: 0.693133, Validation Loss: 0.000660, MSE Loss: 243.597398\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 10, Train Loss: 0.693130, Validation Loss: 0.000660, MSE Loss: 241.670908\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 11, Train Loss: 0.693131, Validation Loss: 0.000660, MSE Loss: 241.073189\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 12, Train Loss: 0.693130, Validation Loss: 0.000660, MSE Loss: 241.327497\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 13, Train Loss: 0.693124, Validation Loss: 0.000660, MSE Loss: 240.489283\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 14, Train Loss: 0.693124, Validation Loss: 0.000660, MSE Loss: 238.950809\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 15, Train Loss: 0.693120, Validation Loss: 0.000660, MSE Loss: 237.589263\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 16, Train Loss: 0.693116, Validation Loss: 0.000660, MSE Loss: 237.436014\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 17, Train Loss: 0.693106, Validation Loss: 0.000660, MSE Loss: 237.162609\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 18, Train Loss: 0.693104, Validation Loss: 0.000660, MSE Loss: 238.440557\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 19, Train Loss: 0.693103, Validation Loss: 0.000660, MSE Loss: 238.318112\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 20, Train Loss: 0.693095, Validation Loss: 0.000660, MSE Loss: 238.369199\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 21, Train Loss: 0.693101, Validation Loss: 0.000660, MSE Loss: 237.218682\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 22, Train Loss: 0.693088, Validation Loss: 0.000660, MSE Loss: 235.528723\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 23, Train Loss: 0.693090, Validation Loss: 0.000660, MSE Loss: 238.038981\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 24, Train Loss: 0.693100, Validation Loss: 0.000660, MSE Loss: 235.782840\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 25, Train Loss: 0.693095, Validation Loss: 0.000660, MSE Loss: 235.688178\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 26, Train Loss: 0.693099, Validation Loss: 0.000660, MSE Loss: 236.358657\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 27, Train Loss: 0.693092, Validation Loss: 0.000660, MSE Loss: 236.650904\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 28, Train Loss: 0.693088, Validation Loss: 0.000660, MSE Loss: 237.254838\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 29, Train Loss: 0.693100, Validation Loss: 0.000660, MSE Loss: 238.896613\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 30, Train Loss: 0.693082, Validation Loss: 0.000660, MSE Loss: 238.384122\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 31, Train Loss: 0.693090, Validation Loss: 0.000660, MSE Loss: 239.763598\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 32, Train Loss: 0.693078, Validation Loss: 0.000660, MSE Loss: 240.377385\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 33, Train Loss: 0.693090, Validation Loss: 0.000660, MSE Loss: 237.466384\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 34, Train Loss: 0.693112, Validation Loss: 0.000660, MSE Loss: 234.236014\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 35, Train Loss: 0.693134, Validation Loss: 0.000660, MSE Loss: 236.144222\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 36, Train Loss: 0.693129, Validation Loss: 0.000660, MSE Loss: 238.089176\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 37, Train Loss: 0.693128, Validation Loss: 0.000660, MSE Loss: 235.763359\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 38, Train Loss: 0.693123, Validation Loss: 0.000660, MSE Loss: 241.827286\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 39, Train Loss: 0.693122, Validation Loss: 0.000660, MSE Loss: 243.925846\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 40, Train Loss: 0.693130, Validation Loss: 0.000660, MSE Loss: 237.265347\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 41, Train Loss: 0.693135, Validation Loss: 0.000660, MSE Loss: 238.720834\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 42, Train Loss: 0.693144, Validation Loss: 0.000660, MSE Loss: 241.047032\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 43, Train Loss: 0.693147, Validation Loss: 0.000660, MSE Loss: 245.042116\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 44, Train Loss: 0.693153, Validation Loss: 0.000660, MSE Loss: 246.693566\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 45, Train Loss: 0.693138, Validation Loss: 0.000660, MSE Loss: 250.279968\n",
      "Current learning rate is: 0.0001\n",
      "Epoch: 46, Train Loss: 0.693147, Validation Loss: 0.000660, MSE Loss: 248.681222\n",
      "Current learning rate is: 0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result_arr1, test_arr1, best_epoch \u001b[38;5;241m=\u001b[39m run_func(X,Y)\n",
      "Cell \u001b[1;32mIn[22], line 27\u001b[0m, in \u001b[0;36mrun_func\u001b[1;34m(X, Y)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m     26\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train(model, train_loader, optimizer, device)\n\u001b[1;32m---> 27\u001b[0m     val_loss, mse_loss \u001b[38;5;241m=\u001b[39m validate(model, val_loader, device)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m#scheduler.step()\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m early_stopping \u001b[38;5;129;01mand\u001b[39;00m val_loss\u001b[38;5;241m<\u001b[39m_bestloss:\n",
      "Cell \u001b[1;32mIn[21], line 38\u001b[0m, in \u001b[0;36mvalidate\u001b[1;34m(model, testloader, device)\u001b[0m\n\u001b[0;32m     35\u001b[0m data, labels \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#calculate test loss\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m p_y \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[0;32m     39\u001b[0m loss_criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m     40\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\Ezzy\\miniconda3\\envs\\Galaxy\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Ezzy\\miniconda3\\envs\\Galaxy\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 135\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_impl(x)\n",
      "Cell \u001b[1;32mIn[16], line 125\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    123\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m    124\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[1;32m--> 125\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_avg_pool:\n\u001b[0;32m    128\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n",
      "File \u001b[1;32mc:\\Users\\Ezzy\\miniconda3\\envs\\Galaxy\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Ezzy\\miniconda3\\envs\\Galaxy\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ezzy\\miniconda3\\envs\\Galaxy\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Ezzy\\miniconda3\\envs\\Galaxy\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Ezzy\\miniconda3\\envs\\Galaxy\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[15], line 128\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    125\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(out)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 128\u001b[0m     identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(x)\n\u001b[0;32m    130\u001b[0m out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m identity\n\u001b[0;32m    131\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[1;32mc:\\Users\\Ezzy\\miniconda3\\envs\\Galaxy\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Ezzy\\miniconda3\\envs\\Galaxy\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ezzy\\miniconda3\\envs\\Galaxy\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Ezzy\\miniconda3\\envs\\Galaxy\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Ezzy\\miniconda3\\envs\\Galaxy\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ezzy\\miniconda3\\envs\\Galaxy\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32mc:\\Users\\Ezzy\\miniconda3\\envs\\Galaxy\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result_arr1, test_arr1, best_epoch = run_func(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training cycle\n",
    "plt.figure(figsize=(10,5))\n",
    "#plt.plot(result_arr1[:,0],result_arr1[:,3],linestyle='-', label='Accuracy')\n",
    "plt.plot(result_arr1[:,0],result_arr1[:,2],linestyle='-', c='orange',label='Validation loss')\n",
    "plt.plot(result_arr1[:,0],result_arr1[:,1],linestyle='-', c='violet',label='Train loss')\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(0,num_epochs-1)\n",
    "#plt.title('NN training cycle')\n",
    "plt.xlabel('Epochs')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Galaxy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
